{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATE & Double Machine Learning\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    "* CATEs - Conditional Average Treatment Effects (Efeitos Heterogêneos do Tratamento)\n",
    "* Efeitos Heterogêneos do Tratamento e o Arcabouço de Resultados Potenciais\n",
    "* Ortogonalização\n",
    "  * Aplicação do Procedimento de Ortogonalização no Python\n",
    "* Ortogonalização e Machine Learning  (Orthogonal/Double Machine Learning - DML)\n",
    "\n",
    "\n",
    "## Referências\n",
    "\n",
    "**Principais:**\n",
    "* UBER CausalML: https://causalml.readthedocs.io/en/latest/\n",
    "* Microsoft EconML: https://econml.azurewebsites.net/\n",
    "* https://github.com/DoubleML/doubleml-for-py\n",
    "* https://docs.doubleml.org/stable/index.html\n",
    "* https://github.com/MasaAsami/ReproducingDMLDiD/blob/main/notebook/Reproduction_of_DMLDiD_RO_for_NEW_SIMDATA.ipynb\n",
    "* https://econml.azurewebsites.net/\n",
    "* Schmidheiny, K., & Siegloch, S. (2023). On event studies and distributed-lags in two-way fixed effects models: Identification, equivalence, and generalization. Journal of Applied Econometrics, 1- 19. https://doi.org/10.1002/jae.2971\n",
    "* Stevenson, Betsey, Wolfers, Justin, 2006. Bargaining in the shadow of the law: Divorce laws and family distress. Q. J. Econ. 121 (1), 267–288.\n",
    "* Goodman-Bacon, A. (2021). Difference-in-differences with variation in treatment timing. Journal of Econometrics. https://doi.org/10.1016/j.jeconom.2021.03.014\n",
    "* Callaway, B. and Sant'Anna, P. H. C. (2021). Difference-in-Differences with multiple time periods. Journal of Econometrics. https://doi.org/10.1016/j.jeconom.2020.12.001\n",
    "\n",
    "**Complementares:**\n",
    "\n",
    "* Borusyak, K.; Jaravel, X. and Spiess, J. (2023). Revisiting Event Study Designs: Robust and Efficient Estimation. arXiv: https://arxiv.org/pdf/2108.12419.pdf\n",
    "* Clément deChaisemartin, Xavier d’Haultfoeuille. (2022) Difference-in-Differences Estimators of Intertemporal Treatment Effects. hal-03873903\n",
    "* Roth et al. (2022) What’s Trending in Difference-in-Differences? A Synthesis of the Recent Econometrics Literature. https://www.jonathandroth.com/assets/files/DiD_Review_Paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CATEs - Conditional Average Treatment Effects (Efeitos Heterogêneos do Tratamento)\n",
    "\n",
    "A nossa função de expectativa condicional é dada por: \n",
    "\n",
    "$$ E[Y|X, T]$$\n",
    "\n",
    "Suponha que queremos realizar inferência causal, entre $T$ e $Y$, sob um contexto $X$, e otimizá-la. Ou seja, \n",
    "\n",
    "$$ \\text{argmax}_{T} E[Y|X, T]$$\n",
    "\n",
    "Ou seja, agora queremos mais do que apenas o efeito médio do tratamento (ATE). Sabemos que o tratamento tem impacto positivo em algumas pessoas, mas não em outras. Os recursos $X$ (covariáveis) desempenham um papel na definição de diferentes perfis de unidades (indivíduos), e cada perfil (indivíduo) **pode responder de forma diferente ao tratamento**. Sendo assim, **agora queremos personalizar o tratamento, dando-o apenas às unidades que melhor respondem a ele** (a ideia é \"direcionar o tratamento\"). Por exemplo, se um medicamento tem efeitos colaterais graves para crianças, podemos querer restringir sua distribuição apenas para adultos. Ou se uma campanha publicitária é eficaz apenas em países de língua inglesa, não vale a pena mostrá-la em outro lugar.\n",
    "\n",
    "**CATE**: \n",
    "\n",
    "O **Conditional Average Treatment Effect** (CATE) é a média do efeito do tratamento condicional a um conjunto de características. Para o caso de tratamento binário, temos: \n",
    "\n",
    "$$ E[Y_{1}-Y_{0}|X]$$\n",
    "\n",
    "ou, para o caso de tratamento contínuo:\n",
    "\n",
    "$$ E[y´(t)|X]$$\n",
    "\n",
    "O condicionamento em $X$ significa que agora permitimos que o efeito do tratamento seja diferente dependendo das características de cada unidade (indivíduo). Queremos tratar apenas as unidades certas (no caso binário) ou descobrir qual é a dosagem de tratamento ideal para cada unidade (no caso contínuo).\n",
    "\n",
    "Considere o exemplo gráfico:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\elast-partition.png\"  alt=\"Imagem\" style=\"width: 400px;\"/>\n",
    "</div>\n",
    "\n",
    "Desagregando os dados, podemos ver que o efeito do tratamento é diferente para diferentes os 3 grupos de pessoas. \n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\elast-split.png\"  alt=\"Imagem\" style=\"width: 800px;\"/>\n",
    "</div>\n",
    "\n",
    "Assim, a ideia é buscar a indetificação do efeito heterogêneo do tratamento, para que possamos personalizar o tratamento para cada unidade. Vamos tentar entender esse mesmo gráfico de outra maneira. Suponha que queremos encontrar os dias em que a $ \\frac{d \\text{Vendas}}{d \\text{Preço}} $ é menor. Isso significa que, para esses dias, a elasticidade-preço é menor. Logo, do ponto de vista do vendedor, poderíamos aumentar o preço nesses dias sem perder muitas vendas (será que isso ocorre no mercado de aluguéis de imóveis durante às férias?).\n",
    "\n",
    "A elasticidade (sensibilidade do indivíduo) é não observável. Podemos pensar cada unidade como tendo um valor $Y_{i}$, com uma elasticidade (sensibilidade) individual ($ \\frac{d Y_{i}}{d T} $). \n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\elasticity.png\"  alt=\"Imagem\" style=\"width: 400px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "Para vermos as inclinações individuais, teríamos que observar cada dia sob dois preços diferentes e calcular como as vendas mudam para cada um desses preços. \n",
    "\n",
    "$$ \\frac{dY_{i}}{dT} = \\frac{Y_{i}(T_{i}) - Y_{i}(T_{i} + \\epsilon)}{T_{i}-(T_{i} + \\epsilon)}$$\n",
    "\n",
    "Este é o problema fundamental da inferência causal novamente. Nunca podemos ver a mesma unidade sob diferentes condições de tratamento. Então, o que podemos fazer?\n",
    "\n",
    "\n",
    "Um possível ajuste aos dados é utilizar o OLS.\n",
    "\n",
    "$$ y_{i} = \\alpha + \\beta T_{i} + \\gamma X_{i} + \\epsilon_{i} $$\n",
    "\n",
    "Diferenciando o tratamento,\n",
    "\n",
    "$$ \\frac{dY_{i}}{dT} = \\beta$$\n",
    "\n",
    "Nesse caso, é um modelo simples, e um valor constante de beta para todos os indivíduos. Esse é o ATE. No entento, se fizermos a seguinte mudança simples:\n",
    "\n",
    "$$ y_{i} = \\alpha + \\beta T_{i} + \\gamma X_{i} + \\delta X_{i}T_{i} + \\epsilon_{i} $$\n",
    "\n",
    "Teremos uma sensibilidade diferente para cada indivíduo:\n",
    "\n",
    "$$ \\frac{dY_{i}}{dT} = \\beta + \\delta X_{i}$$\n",
    "\n",
    "Onde $\\delta$ é um coeficiente que depende das características de cada indivíduo ($X_{i}$). Em outras palavras, a previsão de sensibilidade mudará conforme $X$. Com essas previsões de sensibilidade, podemos agrupar as unidades por quanto achamos que elas responderão ao tratamento.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efeitos Heterogêneos do Tratamento e o Arcabouço de Resultados Potenciais\n",
    "\n",
    "Podemos definir o efeito do tratamento individual (Individual Treatment Effect - ITE - $\\beta_{i}$) como a diferença entre os resultados potenciais. \n",
    "\n",
    "$$ \n",
    "\\beta_{i}^{ITE} = Y_{i}(1) - Y_{i}(0) \n",
    "$$\n",
    "\n",
    "ou, no caso do tratamento contínuo, $ \\beta_{i}^{ITE} = dY_{i}/dt $, onde $t$ é a variável de tratamento. \n",
    "\n",
    "Segundo o problema fundamental da inferência causal, nunca podemos observar o mesmo indivíduo sob diferentes condições de tratamento. \n",
    "\n",
    "$$\n",
    "Y^{obs}_i(t)= \n",
    "\\begin{cases}\n",
    "Y_i(1), & \\text{se } t=1 \\\\\n",
    "Y_i(0), & \\text{se } t=0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Podemos definir o efeito médio do tratamento (Average Treatment Effect - ATE) como\n",
    "\n",
    "$$\n",
    "\\beta^{ATE}= E[Y_i(1) − Y_i(0)] = E[\\beta_i]\n",
    "$$\n",
    "\n",
    "e o efeito do tratamento médio condicional (Conditional Average Treatment Effect - CATE) como\n",
    "\n",
    "\n",
    "$$ \\beta^{CATE}(x) = E[Y_i(1) − Y_i(0)|X] = E[\\beta_i|X_{i}=x] $$\n",
    "\n",
    "**Os ITE são inerentemente não observáveis.**\n",
    "\n",
    "O que pode ser estimado em vez disso é o **Conditional Average Treatment Effect (CATE)** , ou seja, o efeito esperado do tratamento individual, condicional em covariáveis $​​X$.\n",
    "\n",
    "Para recuperar o CATE, precisamo fazer 3 suposições:\n",
    "\n",
    "* Não Confundimento / Inconfundibilidade (Unconfoundedness): \n",
    "\n",
    "$$ Y_{i}(0), Y_{i}(1) \\perp T|X $$\n",
    "\n",
    "* Sobreposição (Overlap): \n",
    "\n",
    "$$ 0 < p(x) < 1 $$\n",
    "\n",
    "* Consistência (Consistency): \n",
    "\n",
    "$$ Y_{i} = Y_{i}(1)T_{i} + Y_{i}(0)(1-T_{i}) $$\n",
    "\n",
    "Onde $p(x)$ é o escore de propensão, ou seja, a probabilidade esperada de ser tratado, condicional às covariáveis ​​$X$.\n",
    "\n",
    "Cabe destacar que os modelos lineares têm algumas desvantagens. A principal delas é a suposição de linearidade em $X$. Seria ótimo se pudéssemos substituir o modelo linear por um modelo de machine learning mais flexível. Poderíamos até mesmo conectar o tratamento como um recurso a um modelo de ML, como Decision Trees, rede neural ou Gradient Boosting. \n",
    "\n",
    "$$ y_{i} = M(X_{i}, T_{i}) + \\epsilon_{i} $$\n",
    "\n",
    "\n",
    "mas a partir daí, não está claro como podemos obter estimativas do efeito do tratamento, uma vez que este modelo produzirá previsões de $Y$, e não de $\\beta$. Vamos aprender uns conceitos importantes para solucionar essa questão.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ortogonalização\n",
    "\n",
    "Antes de estimar o CATE, precisamos conhecer um conceito importante: a Ortogonalização, e como ela é aplicada na econometria. A ideia de ortogonalização é baseada em um teorema elaborado por três econometristas em 1933, Ragnar Frisch, Frederick V. Waugh e Michael C. Lovell. Simplificando, afirma que você pode decompor qualquer modelo de regressão linear multivariável em três estágios ou modelos. \n",
    "\n",
    "Digamos que você tem uma matriz de covariáveis $X$, e voce particiona ela em duas partes, $X_{1}$ e $D$. \n",
    "\n",
    "* **Primeira Etapa**\n",
    "\n",
    "Pegamos o primeiro conjunto de variáveis $X_{1}$ e fazemos uma regressão linear de $X_{1}$ em $Y$, onde $\\theta_{1}$ é o vetor de parâmetros\n",
    "\n",
    "$$ y_{i} = \\theta_{0} + \\theta_{1} X_{1i} + \\epsilon_{i}$$\n",
    "\n",
    "e guardamos os resíduos dessa regressão ($y^{*}$).\n",
    "\n",
    "$$ y^{*}_{i} = y_{i} - \\hat{y}_{i} = y_{i} - ( \\hat{\\theta}_{0} + \\hat{\\theta}_{1} X_{1i} )$$\n",
    "\n",
    "* **Segunda Etapa**\n",
    "\n",
    "Pegamos novamente o primeiro conjunto de características, mas agora executamos um modelo onde estimamos o segundo conjunto de características ($X_{2}$)\n",
    "\n",
    "$$ D_{i} = \\gamma(0) + \\gamma(1) X_{1i} + e_{i}$$\n",
    "\n",
    "Aqui, estamos usando o primeiro conjunto de recursos para prever o segundo conjunto de recursos. Por fim, consideramos também os resíduos desta segunda etapa.\n",
    "\n",
    "$$ D_{i}^{*} = D_{i} - (\\gamma(0) + \\gamma(1) X_{1i})$$\n",
    "\n",
    "* **Terceira etapa**\n",
    "\n",
    "Por fim, pegamos os resíduos do primeiro e do segundo estágio e estimamos o seguinte modelo\n",
    "\n",
    "$$ y_{i}^{*} = \\beta_{0} + \\beta_{2} D_{i}^{*} + e_{i}$$\n",
    "\n",
    "\n",
    "* **Teorema Frisch – Waugh – Lovell (FWL)**\n",
    "\n",
    "O teorema FWL afirma que a estimativa do parâmetro $\\hat{\\beta}_{2}$, estimado anteriormente, é equivalente ao que obtemos ao executar a regressão completa, com todas as covariáveis.\n",
    "\n",
    "$$ y_{i} = \\beta_{0} + \\beta_{1} X_{1i} + \\beta_{2} D_{i} + e_{i}$$\n",
    "\n",
    "\n",
    "**Intuição do teorema FWL**\n",
    "\n",
    "Sabemos que a regressão é um modelo muito especial. Cada um de seus parâmetros tem a interpretação de uma derivada parcial, quanto seria Y se X aumentasse em uma unidade, mantendo todos as outras covariáveis constantes. Sabemos também que se omitirmos variáveis ​​da regressão, teremos viés. Especificamente, viés variável omitido (ou viés de confusão). Ainda assim, Frisch-Waugh-Lovell está dizendo que posso dividir meu modelo de regressão em duas partes, nenhuma delas contendo o conjunto completo de recursos, e ainda assim obter a mesma estimativa que obteria executando a regressão inteira. \n",
    "\n",
    "O teorema fornece algumas dicas sobre o que a regressão linear está fazendo. Para obter o coeficiente de uma variável $X_{k}$, a regressão primeiro usa todas as outras variáveis ​​para prever $X_{k}$ e pega os resíduos. Isso “limpa” $X_{k}$ de qualquer influência dessas variáveis. Dessa forma, quando tentamos entender o impacto de $X_{k}$ sobre $Y$, estará livre de viés de variável omitida. Em segundo lugar, a regressão usa todas as outras variáveis ​​para prever $Y$ e pega os resíduos. Isso “limpa” $Y$ de qualquer influência dessas variáveis, reduzindo a variância de $Y$ para que seja mais fácil ver como $X_{k}$ afeta $Y$.\n",
    "\n",
    "A regressão linear está estimando o impacto de $D$ sobre $y$ enquanto contabiliza $X_{1}$. Isso é importante para inferência causal. \n",
    "\n",
    "Assim, podemos construir um modelo que preveja um tratamento ($T$) usando as covariáveis $X$, um modelo que prevê o resultado $y$ usando as mesmas covariáveis, pega os resíduos de ambos os modelos e executa um modelo que estima como o resíduo de $T$ afeta o resíduo de $y$. Este último modelo vai me dizer como $T$ afeta $y$ enquanto controla por $X$. Ou seja, os dois primeiros modelos controlam as variáveis de confusão. Eles estão gerando dados que são praticamente aleatórios. Isso está distorcendo meus dados. É isso que usamos no modelo final para estimar a elasticidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação do Procedimento de Ortogonalização no Python\n",
    "\n",
    "Vamos aplicar o procedimento de ortogonalização considerando um modelo de regressão linear simples. Vamos realizar a orgonalização supondo linearidade entre as variáveis para entender o conceito. Posteriormente, vamos aplicar o procedimento de ortogonalização em um modelo de machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"https://github.com/Daniel-Uhr/data/raw/main/cattaneo2.dta\")\n",
    "\n",
    "# Criar a variável de resultado\n",
    "df['Y'] = df['bweight']\n",
    "\n",
    "# Criar a variável 'Treated' com valor 1 se 'mbsmoke' for 'smoker', caso contrário 0\n",
    "df['Treated'] = np.where(df['mbsmoke'] == 'smoker', 1, 0)\n",
    "\n",
    "# Criar a variável 'casada' com valor 1 se 'mmarried' for 'married', caso contrário 0\n",
    "df['casada'] = np.where(df['mmarried'] == 'married', 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para desviar este conjunto de dados, precisaremos de dois modelos. O primeiro modelo, vamos chamá-lo $M_{t}(X)$, prevê o tratamento (Se a gestante é fumante, no nosso caso) utilizando os confundidores. É um dos estágios que vimos acima, no teorema de Frisch–Waugh–Lovell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_D = smf.ols(\"Treated ~ 1 + casada + mage + medu + fhisp + mhisp + foreign + alcohol + deadkids + nprenatal + mrace + frace + fage + fedu\", data=df).fit()\n",
    "df['m_D_star'] = df['Treated'] - m_D.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim que tivermos este modelo, construiremos os resíduos\n",
    "\n",
    "$$ \\hat{D}_{i} = D_{i} - M_{t}(X_{i})$$\n",
    "\n",
    "Você pode pensar neste resíduo como uma versão do tratamento que é imparcial ou, melhor ainda, que é impossível de prever a partir dos fatores de confusão $X$. Como os fatores de confusão já eram usados ​​para prever $t$, o resíduo é, por definição, imprevisível com com $X$. Outra maneira de dizer isso é que o viés foi explicado pelo modelo $M_{t}(X)$, produzindo $\\hat{t}_{i}$ que é tão bom quanto atribuído aleatoriamente. É claro que isso só funciona se tivermos em $X$ todos os fatores de confusão que causam ambos $T$ e $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos construir resíduos para o resultado.\n",
    "\n",
    "$$ \\hat{y}_{i} = y_{i} - M_{y}(X_{i})$$\n",
    "\n",
    "\n",
    "Este é outro estágio do teorema de Frisch – Waugh – Lovell. Isso não torna o conjunto menos tendencioso, mas facilita a estimativa do efeito, reduzindo a variância em $y$. Mais uma vez você pode pensar $\\hat{y}_{i}$ como uma versão de $y_{i}$ imprevisível de $X$ ou que teve todas as suas variações devido a $X$ explicadas. Pense nisso. Nós já usamos $X$ para prever $y$ com $M_{y}(X_{i})$. E $\\hat{y}_{i}$ é o erro dessa previsão. Então, por definição, não é possível prever isso a partir de $X$. Todas as informações em $X$ para prever $y$ já foram usadas. Se for esse o caso, a única coisa que resta para explicar $\\hat{y}_{i}$ é algo que não usamos usamos para construí-lo (não incluído em $X$), que é apenas o tratamento (novamente, assumindo que não há fatores de confusão não medidos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_y = smf.ols(\"Y ~  1 + casada + mage + medu + fhisp + mhisp + foreign + alcohol + deadkids + nprenatal + mrace + frace + fage + fedu\", data=df).fit()\n",
    "df['m_y_star'] = df['Y'] - m_y.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando o OLS tradicional com covariáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.104\n",
      "Model:                            OLS   Adj. R-squared:                  0.102\n",
      "Method:                 Least Squares   F-statistic:                     38.49\n",
      "Date:                Mon, 28 Oct 2024   Prob (F-statistic):          5.80e-100\n",
      "Time:                        14:00:17   Log-Likelihood:                -35858.\n",
      "No. Observations:                4642   AIC:                         7.175e+04\n",
      "Df Residuals:                    4627   BIC:                         7.184e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   2851.5203     54.983     51.861      0.000    2743.727    2959.314\n",
      "Treated     -220.0220     21.963    -10.018      0.000    -263.080    -176.964\n",
      "casada        42.7633     23.589      1.813      0.070      -3.482      89.009\n",
      "mage           3.2878      1.935      1.699      0.089      -0.506       7.082\n",
      "medu          -1.5659      4.130     -0.379      0.705      -9.664       6.532\n",
      "fhisp        -22.9258     63.841     -0.359      0.720    -148.084     102.232\n",
      "mhisp         15.0538     68.152      0.221      0.825    -118.557     148.664\n",
      "foreign       -6.8607     39.628     -0.173      0.863     -84.550      70.828\n",
      "alcohol       -9.5560     46.486     -0.206      0.837    -100.690      81.578\n",
      "deadkids     -13.8988     18.872     -0.736      0.461     -50.897      23.099\n",
      "nprenatal     26.1331      2.328     11.225      0.000      21.569      30.697\n",
      "mrace        176.3951     44.950      3.924      0.000      88.272     264.518\n",
      "frace         50.9355     44.172      1.153      0.249     -35.663     137.534\n",
      "fage          -0.9152      1.194     -0.767      0.443      -3.256       1.425\n",
      "fedu           1.0262      3.139      0.327      0.744      -5.128       7.180\n",
      "==============================================================================\n",
      "Omnibus:                      553.208   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1427.823\n",
      "Skew:                          -0.673   Prob(JB):                    8.96e-311\n",
      "Kurtosis:                       5.360   Cond. No.                         485.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "ols = smf.ols(\"Y ~ Treated + 1 + casada + mage + medu + fhisp + mhisp + foreign + alcohol + deadkids + nprenatal + mrace + frace + fage + fedu\", data=df).fit()\n",
    "print(ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos verificar se teorema de Frisch-Waugh-Lovell funciona mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               m_y_star   R-squared:                       0.021\n",
      "Model:                            OLS   Adj. R-squared:                  0.021\n",
      "Method:                 Least Squares   F-statistic:                     100.6\n",
      "Date:                Mon, 28 Oct 2024   Prob (F-statistic):           1.91e-23\n",
      "Time:                        14:00:19   Log-Likelihood:                -35858.\n",
      "No. Observations:                4642   AIC:                         7.172e+04\n",
      "Df Residuals:                    4640   BIC:                         7.173e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   2.348e-11      8.041   2.92e-12      1.000     -15.764      15.764\n",
      "m_D_star    -220.0220     21.932    -10.032      0.000    -263.020    -177.024\n",
      "==============================================================================\n",
      "Omnibus:                      553.208   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1427.823\n",
      "Skew:                          -0.673   Prob(JB):                    8.96e-311\n",
      "Kurtosis:                       5.360   Cond. No.                         2.73\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "FWL1 = smf.ols(\"m_y_star ~ m_D_star\", data=df).fit()\n",
    "print(FWL1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de fazermos as duas transformações, a única coisa que resta para prever esses resíduos é o tratamento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resumir, ao prever o tratamento, construímos $\\hat{t}$ que funciona como uma versão imparcial do tratamento; ao prever o resultado, construímos $\\hat{y}$ que é uma versão do resultado que só pode ser explicada se usarmos o tratamento. Esses dados, onde substituímos por $y$ por $\\hat{y}$ e $t$ por $\\hat{t}$, são os dados desviados que queríamos. Podemos usá-lo para avaliar nosso modelo causal da mesma forma que fizemos anteriormente, usando dados aleatórios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DML - Orthogonal/Double Machine Learning\n",
    "\n",
    "* Double Machine Learning - DML\n",
    "* Double/Debiased Machine Learning - DDML \n",
    "\n",
    "Quando temos muitas possíveis variáveis ​​de controle, podemos querer selecionar as mais relevantes, possivelmente capturando não linearidades e interações. Algoritmos de aprendizado de máquina são perfeitos para essa tarefa. No entanto, nesses casos, estamos introduzindo um viés que é chamado de regularização ou pré-teste, ou viés de seleção de recursos ($X$). \n",
    "\n",
    "Ou seja, o que acontece se a dimensão de $X$ aumenta e não conhecemos a forma funcional através da qual $X$ afeta $Y$ e $D$?\n",
    "\n",
    "Nesses casos, podemos usar **algoritmos de aprendizado de máquina** para **descobrir essas relações não lineares de alta dimensão**.\n",
    "\n",
    "No artigo de **Chernozhukov et al (2018)**, os autores mostraram que também é possível fazer ortogonalização com modelos de aprendizado de máquina. \n",
    "\n",
    "$$ \\hat{y}_{i} = y_{i} - M_{y}(X_{i})$$\n",
    "\n",
    "$$ \\hat{D}_{i} = D_{i} - M_{t}(X_{i})$$\n",
    "\n",
    "\n",
    "***Machine Learning (ML)* e *Overfitting***\n",
    "\n",
    "Os modelos de aprendizado de máquina (ML) podem ajustar-se perfeitamente aos dados, ou melhor, superajustá-los (*Overfitting* / \"sobreajuste\"). \n",
    "\n",
    "  * Apenas olhando para as equações anteriores, podemos saber o que acontecerá nesse caso. Se $M_{y}$ de alguma forma, os resíduos serão todos muito próximos de zero. Se isso acontecer, será difícil descobrir como $t$ afeta isso. \n",
    "\n",
    "  * Da mesma forma, se $M_{t}$ de alguma forma superajusta, seus resíduos também serão próximos de zero. Conseqüentemente, não haverá variação no resíduo do tratamento para ver como isso pode impactar o resultado.\n",
    "\n",
    "  * OBS1: O que podemos fazer para evitar isso o overfitting? A solução é simples: **regularização**. A regularização é uma técnica que adiciona um termo à função de perda que penaliza os coeficientes do modelo. Isso faz com que o modelo seja menos sensível aos dados de treinamento, evitando o superajuste.\n",
    "  * OBS2: Os modelos mais comuns de ML para previsão são: Random Forest, Gradient Boosting, Redes Neurais, Support Vector Machines, etc.\n",
    "    * Random Forest: é um modelo de aprendizado de máquina que pode ser usado tanto para classificação quanto para regressão. Ele é um modelo de conjunto que treina várias árvores de decisão em subconjuntos aleatórios dos dados e faz a média de suas previsões.\n",
    "    * Gradient Boosting: é um modelo de aprendizado de máquina que constrói um modelo aditivo de forma progressiva. Ele permite a otimização de funções de perda diferenciáveis arbitrárias.\n",
    "    * Redes Neurais: são modelos de aprendizado de máquina que são inspirados na forma como o cérebro humano funciona. Eles são compostos por camadas de neurônios que processam e transmitem informações.\n",
    "    * Support Vector Machines: são modelos de aprendizado de máquina que são usados para classificação e regressão. Eles são eficazes em espaços de alta dimensão e são capazes de lidar com dados não lineares.\n",
    "    * Outros modelos de ML mais usados em economia são: LASSO, Ridge, Elastic Net, etc. LASSO é um método de regressão que adiciona uma penalidade L1 à função de perda. Isso faz com que alguns coeficientes sejam exatamente zero, o que é útil para seleção de recursos. Ridge é um método de regressão que adiciona uma penalidade L2 à função de perda. Isso faz com que os coeficientes sejam menores, o que é útil para reduzir a variância. Elastic Net é um método de regressão que combina as penalidades L1 e L2. Isso permite que você selecione recursos e reduza a variância ao mesmo tempo.\n",
    "\n",
    "**Validação Cruzada (Cross-Validation)**\n",
    "\n",
    "Para explicar esse procedimemto, precisamos fazer a divisão da amostra. Ou seja, estimamos o modelo com uma parte do conjunto de dados e fazemos previsões na outra parte. Uma maneira simples e intuitiva seria dividir a amostra de teste ao meio, fazer dois modelos de forma que cada um seja estimado em uma metade do conjunto de dados e faça previsões na outra metade.\n",
    "\n",
    "Já uma implementação um pouco mais elegante usa a chamada **validação cruzada K-fold**. Ist\n",
    "\n",
    "\n",
    "\n",
    "A vantagem é que podemos treinar todos os modelos em uma amostra maior que metade do conjunto de teste.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\kfold-cv.png\"  alt=\"Imagem\" style=\"width: 450px;\"/>\n",
    "</div>\n",
    "\n",
    "Felizmente, esse tipo de previsão cruzada é muito fácil de implementar usando `cross_val_predicta` função do Sklearn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar o Random Forest para fazer a previsão do tratamento e do resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = ['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol', 'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']\n",
    "D = \"Treated\"\n",
    "y = \"Y\"\n",
    "\n",
    "folds = 5\n",
    "\n",
    "np.random.seed(123)\n",
    "m_D = RandomForestRegressor(n_estimators=100)\n",
    "D_res1 = df[D] - cross_val_predict(m_D, df[X], df[D], cv=folds)\n",
    "\n",
    "m_y = RandomForestRegressor(n_estimators=100)\n",
    "y_res1 = df[y] - cross_val_predict(m_y, df[X], df[y], cv=folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos os resíduos, vamos armazená-los como colunas em um novo conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bweight</th>\n",
       "      <th>mmarried</th>\n",
       "      <th>mhisp</th>\n",
       "      <th>fhisp</th>\n",
       "      <th>foreign</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>deadkids</th>\n",
       "      <th>mage</th>\n",
       "      <th>medu</th>\n",
       "      <th>fage</th>\n",
       "      <th>...</th>\n",
       "      <th>lbweight</th>\n",
       "      <th>fbaby</th>\n",
       "      <th>prenatal1</th>\n",
       "      <th>Y</th>\n",
       "      <th>Treated</th>\n",
       "      <th>casada</th>\n",
       "      <th>m_D_star</th>\n",
       "      <th>m_y_star</th>\n",
       "      <th>Y-ML_y(X)</th>\n",
       "      <th>Treated-ML_t(X)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3459</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3459</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.086026</td>\n",
       "      <td>47.203835</td>\n",
       "      <td>-295.130000</td>\n",
       "      <td>-0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3260</td>\n",
       "      <td>notmarried</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.315814</td>\n",
       "      <td>277.930277</td>\n",
       "      <td>303.140000</td>\n",
       "      <td>-0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3572</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3572</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.186338</td>\n",
       "      <td>196.895284</td>\n",
       "      <td>132.310000</td>\n",
       "      <td>-0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2948</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2948</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.156887</td>\n",
       "      <td>-451.977522</td>\n",
       "      <td>-460.669000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2410</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2410</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.121311</td>\n",
       "      <td>-1040.633348</td>\n",
       "      <td>-1350.973333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bweight    mmarried  mhisp  fhisp  foreign  alcohol  deadkids  mage  medu  \\\n",
       "0     3459     married      0      0        0        0         0    24    14   \n",
       "1     3260  notmarried      0      0        1        0         0    20    10   \n",
       "2     3572     married      0      0        1        0         0    22     9   \n",
       "3     2948     married      0      0        0        0         0    26    12   \n",
       "4     2410     married      0      0        0        0         0    20    12   \n",
       "\n",
       "   fage  ...  lbweight  fbaby  prenatal1     Y Treated casada  m_D_star  \\\n",
       "0    28  ...         0     No        Yes  3459       0      1 -0.086026   \n",
       "1     0  ...         0     No        Yes  3260       0      0 -0.315814   \n",
       "2    30  ...         0     No        Yes  3572       0      1 -0.186338   \n",
       "3    30  ...         0     No        Yes  2948       0      1 -0.156887   \n",
       "4    21  ...         1    Yes        Yes  2410       0      1 -0.121311   \n",
       "\n",
       "      m_y_star    Y-ML_y(X)  Treated-ML_t(X)  \n",
       "0    47.203835  -295.130000        -0.026667  \n",
       "1   277.930277   303.140000        -0.410000  \n",
       "2   196.895284   132.310000        -0.070000  \n",
       "3  -451.977522  -460.669000         0.000000  \n",
       "4 -1040.633348 -1350.973333         0.000000  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DML1 = df.assign(**{\n",
    "    \"Y-ML_y(X)\": y_res1,\n",
    "    \"Treated-ML_t(X)\": D_res1,\n",
    "})\n",
    "DML1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 y_res1   R-squared:                       0.014\n",
      "Model:                            OLS   Adj. R-squared:                  0.014\n",
      "Method:                 Least Squares   F-statistic:                     66.82\n",
      "Date:                Mon, 28 Oct 2024   Prob (F-statistic):           3.80e-16\n",
      "Time:                        14:00:42   Log-Likelihood:                -36189.\n",
      "No. Observations:                4642   AIC:                         7.238e+04\n",
      "Df Residuals:                    4640   BIC:                         7.239e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.1388      8.646      0.479      0.632     -12.812      21.089\n",
      "D_res1      -182.0597     22.272     -8.174      0.000    -225.723    -138.396\n",
      "==============================================================================\n",
      "Omnibus:                      289.287   Durbin-Watson:                   1.991\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              619.258\n",
      "Skew:                          -0.414   Prob(JB):                    3.39e-135\n",
      "Kurtosis:                       4.587   Cond. No.                         2.58\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "FWL_DML1 = smf.ols(\"y_res1 ~ D_res1\", data=DML1).fit()\n",
    "print(FWL_DML1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos outro exemplo do DML. Considerando Gradient Boosting Machines (GBM) para prever o tratamento e o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Definir as variáveis X, D, y\n",
    "X = ['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol', 'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']\n",
    "D = \"Treated\"\n",
    "y = \"Y\"\n",
    "\n",
    "# Definir o número de folds para a validação cruzada\n",
    "folds = 5\n",
    "\n",
    "# Garantir reprodutibilidade nos modelos de Gradient Boosting\n",
    "m_D = GradientBoostingRegressor(n_estimators=100, random_state=123)\n",
    "D_res2 = df[D] - cross_val_predict(m_D, df[X], df[D], cv=folds)\n",
    "\n",
    "m_y = GradientBoostingRegressor(n_estimators=100, random_state=123)\n",
    "y_res2 = df[y] - cross_val_predict(m_y, df[X], df[y], cv=folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bweight</th>\n",
       "      <th>mmarried</th>\n",
       "      <th>mhisp</th>\n",
       "      <th>fhisp</th>\n",
       "      <th>foreign</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>deadkids</th>\n",
       "      <th>mage</th>\n",
       "      <th>medu</th>\n",
       "      <th>fage</th>\n",
       "      <th>...</th>\n",
       "      <th>lbweight</th>\n",
       "      <th>fbaby</th>\n",
       "      <th>prenatal1</th>\n",
       "      <th>Y</th>\n",
       "      <th>Treated</th>\n",
       "      <th>casada</th>\n",
       "      <th>m_D_star</th>\n",
       "      <th>m_y_star</th>\n",
       "      <th>Y-ML_y(X)</th>\n",
       "      <th>Treated-ML_t(X)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3459</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3459</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.086026</td>\n",
       "      <td>47.203835</td>\n",
       "      <td>44.846311</td>\n",
       "      <td>-0.065141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3260</td>\n",
       "      <td>notmarried</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.315814</td>\n",
       "      <td>277.930277</td>\n",
       "      <td>173.141492</td>\n",
       "      <td>-0.379986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3572</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3572</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.186338</td>\n",
       "      <td>196.895284</td>\n",
       "      <td>84.286938</td>\n",
       "      <td>-0.182789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2948</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2948</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.156887</td>\n",
       "      <td>-451.977522</td>\n",
       "      <td>-412.680405</td>\n",
       "      <td>-0.171932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2410</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2410</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.121311</td>\n",
       "      <td>-1040.633348</td>\n",
       "      <td>-1096.367541</td>\n",
       "      <td>-0.070470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bweight    mmarried  mhisp  fhisp  foreign  alcohol  deadkids  mage  medu  \\\n",
       "0     3459     married      0      0        0        0         0    24    14   \n",
       "1     3260  notmarried      0      0        1        0         0    20    10   \n",
       "2     3572     married      0      0        1        0         0    22     9   \n",
       "3     2948     married      0      0        0        0         0    26    12   \n",
       "4     2410     married      0      0        0        0         0    20    12   \n",
       "\n",
       "   fage  ...  lbweight  fbaby  prenatal1     Y Treated casada  m_D_star  \\\n",
       "0    28  ...         0     No        Yes  3459       0      1 -0.086026   \n",
       "1     0  ...         0     No        Yes  3260       0      0 -0.315814   \n",
       "2    30  ...         0     No        Yes  3572       0      1 -0.186338   \n",
       "3    30  ...         0     No        Yes  2948       0      1 -0.156887   \n",
       "4    21  ...         1    Yes        Yes  2410       0      1 -0.121311   \n",
       "\n",
       "      m_y_star    Y-ML_y(X)  Treated-ML_t(X)  \n",
       "0    47.203835    44.846311        -0.065141  \n",
       "1   277.930277   173.141492        -0.379986  \n",
       "2   196.895284    84.286938        -0.182789  \n",
       "3  -451.977522  -412.680405        -0.171932  \n",
       "4 -1040.633348 -1096.367541        -0.070470  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DML2 = df.assign(**{\n",
    "    \"Y-ML_y(X)\": y_res2,\n",
    "    \"Treated-ML_t(X)\": D_res2,\n",
    "})\n",
    "DML2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 y_res2   R-squared:                       0.019\n",
      "Model:                            OLS   Adj. R-squared:                  0.018\n",
      "Method:                 Least Squares   F-statistic:                     88.46\n",
      "Date:                Mon, 28 Oct 2024   Prob (F-statistic):           7.93e-21\n",
      "Time:                        14:00:50   Log-Likelihood:                -35882.\n",
      "No. Observations:                4642   AIC:                         7.177e+04\n",
      "Df Residuals:                    4640   BIC:                         7.178e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.7775      8.082      0.096      0.923     -15.067      16.622\n",
      "D_res2      -209.0031     22.221     -9.405      0.000    -252.568    -165.439\n",
      "==============================================================================\n",
      "Omnibus:                      476.984   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1222.895\n",
      "Skew:                          -0.589   Prob(JB):                    2.83e-266\n",
      "Kurtosis:                       5.222   Cond. No.                         2.75\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "FWL_DML2 = smf.ols(\"y_res2 ~ D_res2\", data=DML2).fit()\n",
    "print(FWL_DML2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos a mecânica do DML. \n",
    "\n",
    "Mas qual o melhor modelo de ML para prever o tratamento e o resultado? \n",
    "\n",
    "Precisamos avaliar, um critério de decisão comum é utilizar o erro quadrático médio (MSE) dos resíduos gerados para $D$ e $Y$ para ambos os modelos, e então comparar seus desempenhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for D - Random Forest: 0.15049072305334754\n",
      "MSE for y - Random Forest: 350812.5710231999\n",
      "MSE for D - Gradient Boosting: 0.1322742607784923\n",
      "MSE for y - Gradient Boosting: 309191.01191423537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Definir as variáveis\n",
    "X = ['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol', 'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']\n",
    "D = \"Treated\"\n",
    "y = \"Y\"\n",
    "folds = 5\n",
    "\n",
    "# RandomForest - Estimando m_D e m_y\n",
    "rf_model_D = RandomForestRegressor(n_estimators=100)\n",
    "D_res_rf = df[D] - cross_val_predict(rf_model_D, df[X], df[D], cv=folds)\n",
    "\n",
    "rf_model_y = RandomForestRegressor(n_estimators=100)\n",
    "y_res_rf = df[y] - cross_val_predict(rf_model_y, df[X], df[y], cv=folds)\n",
    "\n",
    "# GradientBoosting - Estimando m_D e m_y\n",
    "gb_model_D = GradientBoostingRegressor(n_estimators=100)\n",
    "D_res_gb = df[D] - cross_val_predict(gb_model_D, df[X], df[D], cv=folds)\n",
    "\n",
    "gb_model_y = GradientBoostingRegressor(n_estimators=100)\n",
    "y_res_gb = df[y] - cross_val_predict(gb_model_y, df[X], df[y], cv=folds)\n",
    "\n",
    "# Calculando o MSE para cada modelo\n",
    "mse_D_rf = mean_squared_error(df[D], df[D] - D_res_rf)  # Random Forest para D\n",
    "mse_y_rf = mean_squared_error(df[y], df[y] - y_res_rf)  # Random Forest para y\n",
    "\n",
    "mse_D_gb = mean_squared_error(df[D], df[D] - D_res_gb)  # Gradient Boosting para D\n",
    "mse_y_gb = mean_squared_error(df[y], df[y] - y_res_gb)  # Gradient Boosting para y\n",
    "\n",
    "# Exibir os resultados de MSE\n",
    "print(\"MSE for D - Random Forest:\", mse_D_rf)\n",
    "print(\"MSE for y - Random Forest:\", mse_y_rf)\n",
    "print(\"MSE for D - Gradient Boosting:\", mse_D_gb)\n",
    "print(\"MSE for y - Gradient Boosting:\", mse_y_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparação para $D$ (Variável de Tratamento):\n",
    "\n",
    "* Random Forest MSE: 0.1506\n",
    "* Gradient Boosting MSE: 0.1323\n",
    "\n",
    "Aqui, o Gradient Boosting tem um desempenho melhor na predição de $D$, pois seu MSE é menor. Isso significa que ele foi mais eficiente na captura da relação entre as variáveis explicativas $X$ e o tratamento $D$, resultando em resíduos menores.\n",
    "\n",
    "Comparação para $Y$\n",
    "* Random Forest MSE: 352060.35\n",
    "* Gradient Boosting MSE: 309063.98\n",
    "\n",
    "Novamente, o Gradient Boosting apresenta um MSE menor na predição de $y$, indicando que ele conseguiu capturar melhor a relação entre as variáveis explicativas  $X$ e o resultado $Y$, quando comparado ao Random Forest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos fazer de forma geral a análise para diversos modelos e verificar qual o melhor baseados no critério de erro quadrado médio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "  MSE for D: 0.15139084627531682\n",
      "  MSE for y: 349909.7289144392\n",
      "\n",
      "Model: GradientBoosting\n",
      "  MSE for D: 0.1322770984849905\n",
      "  MSE for y: 309273.4665657201\n",
      "\n",
      "Model: Lasso\n",
      "  MSE for D: 0.14514535464451975\n",
      "  MSE for y: 308621.37257196667\n",
      "\n",
      "Model: Ridge\n",
      "  MSE for D: 0.13530450869509936\n",
      "  MSE for y: 308669.9810617438\n",
      "\n",
      "Model: ElasticNet\n",
      "  MSE for D: 0.14369145438382802\n",
      "  MSE for y: 308710.90380429785\n",
      "\n",
      "Model: MLP\n",
      "  MSE for D: 0.1431742709965872\n",
      "  MSE for y: 363171.59636381926\n",
      "\n",
      "Model: SVR\n",
      "  MSE for D: 0.1582687258940923\n",
      "  MSE for y: 330887.97070007736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Definir os modelos que vamos testar\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=100),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    \"MLP\": MLPRegressor(hidden_layer_sizes=(50,), max_iter=1000),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "# Definir as variáveis\n",
    "X = ['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol', 'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']\n",
    "D = \"Treated\"\n",
    "y = \"Y\"\n",
    "folds = 5\n",
    "\n",
    "# Dicionário para armazenar os MSE de cada modelo para D e y\n",
    "mse_results = {}\n",
    "\n",
    "# Loop para ajustar os modelos e calcular os MSE para D e y\n",
    "for name, model in models.items():\n",
    "    # Estimativa de D com validação cruzada\n",
    "    D_res = df[D] - cross_val_predict(model, df[X], df[D], cv=folds)\n",
    "    # Estimativa de y com validação cruzada\n",
    "    y_res = df[y] - cross_val_predict(model, df[X], df[y], cv=folds)\n",
    "    \n",
    "    # Calcular MSE para D e y\n",
    "    mse_D = mean_squared_error(df[D], df[D] - D_res)\n",
    "    mse_y = mean_squared_error(df[y], df[y] - y_res)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    mse_results[name] = {\"MSE for D\": mse_D, \"MSE for y\": mse_y}\n",
    "\n",
    "# Exibir os resultados\n",
    "for model_name, mse in mse_results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"  MSE for D: {mse['MSE for D']}\")\n",
    "    print(f\"  MSE for y: {mse['MSE for y']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para os resíduos de $D$: O Gradient Boosting é o modelo preferido, pois ele obteve o menor MSE para prever a variável de tratamento.\n",
    "\n",
    "Para os resíduos de $y$: O Lasso foi o melhor em prever o resultado.\n",
    "\n",
    "Vou aumentar o número fold para 8 e verificar se os resultados mudam. Esse aumento de 5 para 8 folds é importante para garantir que o modelo seja treinado em uma amostra maior, o que pode melhorar a precisão das previsões. Além de ser uma prática para verificar a robustez dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "  MSE for D: 0.1520980970340551\n",
      "  MSE for y: 349468.8053384342\n",
      "\n",
      "Model: GradientBoosting\n",
      "  MSE for D: 0.13244114694873113\n",
      "  MSE for y: 308077.9936950858\n",
      "\n",
      "Model: Lasso\n",
      "  MSE for D: 0.14517956178493543\n",
      "  MSE for y: 308414.018017211\n",
      "\n",
      "Model: Ridge\n",
      "  MSE for D: 0.13535137678662412\n",
      "  MSE for y: 308426.02969660814\n",
      "\n",
      "Model: ElasticNet\n",
      "  MSE for D: 0.1437445145464821\n",
      "  MSE for y: 308393.73652545904\n",
      "\n",
      "Model: MLP\n",
      "  MSE for D: 0.14012366416355287\n",
      "  MSE for y: 352474.1787789329\n",
      "\n",
      "Model: SVR\n",
      "  MSE for D: 0.1582865914491929\n",
      "  MSE for y: 330487.8627229285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Definir os modelos que vamos testar\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=100),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    \"MLP\": MLPRegressor(hidden_layer_sizes=(50,), max_iter=1000),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "# Definir as variáveis\n",
    "X = ['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol', 'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']\n",
    "D = \"Treated\"\n",
    "y = \"Y\"\n",
    "folds = 8\n",
    "\n",
    "# Dicionário para armazenar os MSE de cada modelo para D e y\n",
    "mse_results = {}\n",
    "\n",
    "# Loop para ajustar os modelos e calcular os MSE para D e y\n",
    "for name, model in models.items():\n",
    "    # Estimativa de D com validação cruzada\n",
    "    D_res = df[D] - cross_val_predict(model, df[X], df[D], cv=folds)\n",
    "    # Estimativa de y com validação cruzada\n",
    "    y_res = df[y] - cross_val_predict(model, df[X], df[y], cv=folds)\n",
    "    \n",
    "    # Calcular MSE para D e y\n",
    "    mse_D = mean_squared_error(df[D], df[D] - D_res)\n",
    "    mse_y = mean_squared_error(df[y], df[y] - y_res)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    mse_results[name] = {\"MSE for D\": mse_D, \"MSE for y\": mse_y}\n",
    "\n",
    "# Exibir os resultados\n",
    "for model_name, mse in mse_results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"  MSE for D: {mse['MSE for D']}\")\n",
    "    print(f\"  MSE for y: {mse['MSE for y']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentando para 8 folds, o Gradient Boosting torna-se o melhor modelo para prever tanto o tratamento quanto o resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from econml.dml import LinearDML\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimativa do Efeito Causal Médio (ATE): -185.54586945953977\n",
      "Intervalo de Confiança para o ATE: (-237.53567774646416, -133.5560611726154)\n"
     ]
    }
   ],
   "source": [
    "# Definir as variáveis\n",
    "X = df[['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol', 'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']]\n",
    "D = df['Treated']\n",
    "y = df['Y']\n",
    "\n",
    "# Converter variáveis categóricas em dummies (se necessário)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Dividir os dados em treino e teste (opcional, pois o EconML faz validação cruzada internamente)\n",
    "# X_train, X_test, D_train, D_test, y_train, y_test = train_test_split(X, D, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Definir os modelos de Machine Learning para o modelo condicional de tratamento e resultado\n",
    "model_y = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "model_t = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "# Criar o estimador LinearDML\n",
    "estimator = LinearDML(model_y=model_y,\n",
    "                      model_t=model_t,\n",
    "                      discrete_treatment=True,\n",
    "                      random_state=123)\n",
    "\n",
    "# Ajustar o modelo\n",
    "estimator.fit(y, D, X=X)\n",
    "\n",
    "# Obter o efeito causal médio\n",
    "ate = estimator.ate(X=X)\n",
    "print(\"Estimativa do Efeito Causal Médio (ATE):\", ate)\n",
    "\n",
    "# Obter o intervalo de confiança\n",
    "ate_interval = estimator.ate_interval(X=X)\n",
    "print(\"Intervalo de Confiança para o ATE:\", ate_interval)\n",
    "\n",
    "# Obter o efeito heterogêneo (se necessário)\n",
    "# te = estimator.effect(X=X)\n",
    "# print(\"Efeito Tratamento Heterogêneo:\", te)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimação do CATE com DML\n",
    "\n",
    "Até agora, vimos como o Double/Debiased ML (Double Machine Learning - DML) nos permite focar na estimativa do Efeito Médio do Tratamento (ATE). No entanto, ele também pode ser usado para estimar a heterogeneidade dos efeitos do tratamento ou o Efeito Médio Condicional do Tratamento (CATE). \n",
    "\n",
    "Logo, o CATE para modelos DoubleMLPLR consideram uma versão ligeiramente ajustada do modelo DoubleMLPLR. Em vez de considerar um efeito de tratamento constante para todas as observações, o modelo ajustado permite um efeito diferente com base em grupos.\n",
    "\n",
    "$$ Y = D \\theta_{0} (X) + g_{0}(X) + \\epsilon$$\n",
    "\n",
    "com  $E(\\epsilon|D,X)=0$, e\n",
    "\n",
    "$$ D = m_{0}(X) + \\eta$$\n",
    "\n",
    "com $E(\\eta|X)=0$.\n",
    "\n",
    "onde $\\theta_{0}(X)$ é o efeito heterogêneo do tratamento.\n",
    "\n",
    "Ou seja, o CATE $\\Theta_{ij}(X)$ tem a seguinte forma:\n",
    "\n",
    "$$ \\Theta_{i}(X) = X' coef_{ij} + cate\\_intercept_{ij}$$\n",
    "\n",
    "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Coefficient Results                       \n",
      "================================================================\n",
      "          point_estimate  stderr zstat  pvalue ci_lower ci_upper\n",
      "----------------------------------------------------------------\n",
      "casada             8.846  57.364  0.154  0.877 -103.584  121.277\n",
      "mage             -11.047   5.421 -2.038  0.042  -21.672   -0.423\n",
      "medu              26.091  10.723  2.433  0.015    5.074   47.107\n",
      "fhisp              21.56 126.313  0.171  0.864 -226.009  269.129\n",
      "mhisp            -164.88 144.534 -1.141  0.254 -448.161  118.402\n",
      "foreign           435.58  132.44  3.289  0.001  176.003  695.158\n",
      "alcohol          -20.385  95.108 -0.214   0.83 -206.793  166.022\n",
      "deadkids          41.641  55.025  0.757  0.449  -66.206  149.489\n",
      "nprenatal         -8.174   7.046  -1.16  0.246  -21.983    5.635\n",
      "mrace           -143.311 103.668 -1.382  0.167 -346.496   59.874\n",
      "frace            -19.611  97.655 -0.201  0.841  -211.01  171.789\n",
      "fage              -0.933   2.945 -0.317  0.751   -6.705    4.838\n",
      "fedu              -1.335   8.278 -0.161  0.872   -17.56    14.89\n",
      "                       CATE Intercept Results                       \n",
      "====================================================================\n",
      "               point_estimate  stderr zstat pvalue ci_lower ci_upper\n",
      "--------------------------------------------------------------------\n",
      "cate_intercept          7.624 161.015 0.047  0.962  -307.96  323.208\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
      "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
      "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
      "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
      "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n"
     ]
    }
   ],
   "source": [
    "print(estimator.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretação:**\n",
    "\n",
    "* mage (idade da mãe):\n",
    "  * point_estimate: -11.047 (pvalue: 0.042)\n",
    "  * Isso sugere que, para cada aumento de um ano na idade da mãe, o efeito negativo de fumar durante a gravidez no peso ao nascer aumenta em 11.047 gramas (ou seja, o efeito se torna mais negativo).\n",
    "  * Há evidência estatística de que a idade da mãe influencia o efeito de fumar durante a gravidez sobre o peso ao nascer.\n",
    "\n",
    "* medu (educação materna):\n",
    "  * point_estimate: 26.091 (pvalue: 0.015)\n",
    "  * Para cada ano adicional de educação da mãe, o efeito negativo de fumar durante a gravidez no peso ao nascer é reduzido em 26.091 gramas (o efeito negativo é mitigado).\n",
    "  * A educação materna parece reduzir o impacto negativo de fumar durante a gravidez.\n",
    "\n",
    "* foreign (se a mãe é estrangeira):\n",
    "  * point_estimate: 435.58 (pvalue: 0.001 (altamente significativo))\n",
    "  * Interpretation: Mães estrangeiras têm um efeito tratamento condicional que é 435.58 gramas maior do que o de mães não estrangeiras.\n",
    "  * A origem estrangeira da mãe está associada a uma redução significativa do efeito negativo de fumar durante a gravidez.\n",
    "\n",
    "* Outras variáveis: Algumas covariáveis não são estatisticamente significativas (pvalue > 0.05), indicando que não há evidência suficiente para afirmar que essas covariáveis influenciam o efeito do tratamento.\n",
    "\n",
    "* CATE Intercept Results (Resultados do Intercepto do CATE):\n",
    "  * cate_intercept: 7.624\n",
    "  * Este é o valor base do efeito tratamento condicional quando todas as covariáveis estão em zero. Como zero pode não ser um valor interpretável para algumas covariáveis (por exemplo, idade da mãe), o intercepto isoladamente pode não ter uma interpretação prática direta.\n",
    "\n",
    "* OBS: Covariáveis contínuas vs. categóricas: Para variáveis contínuas (como mage), o coeficiente representa a variação no efeito do tratamento por unidade de aumento na covariável. Para variáveis binárias (como foreign), o coeficiente representa a diferença no efeito do tratamento entre os grupos (por exemplo, estrangeiras vs. não estrangeiras).\n",
    "\n",
    "\n",
    "**Resumo:**\n",
    "\n",
    "* O modelo estima que o efeito do tratamento (fumar durante a gravidez) sobre o peso ao nascer não é constante, mas varia linearmente com as covariáveis $X$. O sinal e magnitude dos coeficientes indicam a direção e a intensidade com que cada covariável afeta o efeito do tratamento.\n",
    "* O impacto de fumar durante a gravidez no peso ao nascer não é o mesmo para todas as mães; varia de acordo com características como idade, educação e nacionalidade.\n",
    "* Os resultados sugerem que políticas públicas visando reduzir o tabagismo durante a gravidez podem ser mais eficazes se levarem em consideração essas características. Por exemplo, focar em mães mais jovens ou com menor nível educacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
    "\n",
    "$$ Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon $$\n",
    "\n",
    "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
    "$$ \\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$$\n",
    "\n",
    "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efeito Tratamento Heterogêneo: [-175.54672274  434.12075885  159.15035232 ...  -47.47973106 -224.89001684\n",
      " -214.77611673]\n"
     ]
    }
   ],
   "source": [
    "# Obter o efeito heterogêneo (se necessário)\n",
    "te = estimator.effect(X=X)\n",
    "print(\"Efeito Tratamento Heterogêneo:\", te)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar diretamente ou o pacote EconML, ou DoubleML, que é uma biblioteca Python para estimar e inferir sobre os efeitos heterogêneos do tratamento. \n",
    "\n",
    "Cabe destacar que o DoubleML estima:\n",
    "* Partially linear regression (PLR) - DoubleMLPLR\n",
    "* Partially linear IV regression models (PLIV) - DoubleMLPLIV\n",
    "* Interactive regression models (IRM) - DoubleMLIRM\n",
    "* Interactive IV regression models (IIVM) - DoubleIIVM\n",
    "\n",
    "No caso do nosso exemplo, vamos utilizar o DoubleMLPLR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLPLR Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: Y\n",
      "Treatment variable(s): ['Treated']\n",
      "Covariates: ['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol', 'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 4642\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: GradientBoostingRegressor(random_state=123)\n",
      "Learner ml_m: GradientBoostingRegressor(random_state=123)\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_l RMSE: [[554.57781169]]\n",
      "Learner ml_m RMSE: [[0.3626963]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "               coef    std err         t         P>|t|       2.5 %      97.5 %\n",
      "Treated -204.390708  22.513418 -9.078617  1.099629e-19 -248.516197 -160.265219\n"
     ]
    }
   ],
   "source": [
    "from doubleml import DoubleMLData, DoubleMLPLR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Definir X, D, y \n",
    "X = ['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol', 'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']  \n",
    "D = \"Treated\"  \n",
    "y = \"Y\" \n",
    "\n",
    "# Configurando o DoubleMLData\n",
    "dml_data = DoubleMLData(df, y_col=y, d_cols=D, x_cols=X)\n",
    "\n",
    "# Ajustar Gradient Boosting com random_state para garantir reprodutibilidade (learner / Aprendiz)\n",
    "ml_gb = GradientBoostingRegressor(n_estimators=100, random_state=123)\n",
    "\n",
    "# Definir a seed na validação cruzada\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Configurar o estimador Double Machine Learning para Regressão Linear Parcial (PLR)\n",
    "dml_plr = DoubleMLPLR(dml_data, ml_gb, ml_gb, n_folds=5).fit()\n",
    "\n",
    "# Exibir o resultado do DML\n",
    "print(dml_plr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre que no *Partially linear regression model (PLR)* a interpretação causal depende da exogeneidade condicional, o que requer controlar variáveis de confusão. O DoubleML implementa a análise de sensibilidade em relação a confundidores omitidos.\n",
    "\n",
    "Vamos adicionar parâmetros de sensibilidade (possiveis confundidores omitidos)\n",
    "* cf_y: efeito que um confundidor não observado teria sobre a variável dependente\n",
    "* cf_d:representa o impacto de um confundidor omitido sobre $D$.\n",
    "\n",
    "Utilizamos valores hipotéticos, com base no que se acredita que os confundidores omitidos podem estar influenciando em termos percentuais $D$ ou $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sensitivity Analysis ==================\n",
      "\n",
      "------------------ Scenario          ------------------\n",
      "Significance Level: level=0.95\n",
      "Sensitivity parameters: cf_y=0.04; cf_d=0.03, rho=1.0\n",
      "\n",
      "------------------ Bounds with CI    ------------------\n",
      "    CI lower  theta lower       theta  theta upper    CI upper\n",
      "0 -294.76542  -257.688472 -204.390708  -151.092945 -114.030333\n",
      "\n",
      "------------------ Robustness Values ------------------\n",
      "   H_0     RV (%)    RVa (%)\n",
      "0  0.0  12.609113  10.430682\n"
     ]
    }
   ],
   "source": [
    "dml_plr.sensitivity_analysis(cf_y=0.04, cf_d=0.03)\n",
    "print(dml_plr.sensitivity_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Estimativa Original: -208.978\n",
    "* Robustez\n",
    "  * H0: Assume que o efeito do tratamento é zero.\n",
    "  * RV(%): O valor de 12.85% indica que, se os confundidores omitidos explicassem até 12.85% da variância da variável de tratamento $D$, a estimativa de $\\theta$ perderia significância estatística.\n",
    "  * RVa (%): O valor de 10.67% refere-se a uma versão ajustada do RV, levando em conta a variância da variável de resposta $Y$. Se confundidores omitidos explicassem até $10.67%$ da variância de $Y$, a significância também seria perdida.\n",
    "\n",
    "Os resultados da análise de sensibilidade sugerem que sua estimativa causal de $-208.978$ é relativamente robusta. Para que a estimativa perca significância estatística, os confundidores omitidos teriam que explicar cerca de $12.85%$ da variância de $D$, o que indica uma certa robustez do efeito causal em relação à omissão de variáveis de confusão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimação do CATE com DML\n",
    "\n",
    "Até agora, vimos como o Double/Debiased ML (Double Machine Learning - DML) nos permite focar na estimativa do Efeito Médio do Tratamento (ATE). No entanto, ele também pode ser usado para estimar a heterogeneidade dos efeitos do tratamento ou o Efeito Médio Condicional do Tratamento (CATE). \n",
    "\n",
    "Logo, o CATE para modelos DoubleMLPLR consideram uma versão ligeiramente ajustada do modelo DoubleMLPLR. Em vez de considerar um efeito de tratamento constante para todas as observações, o modelo ajustado permite um efeito diferente com base em grupos.\n",
    "\n",
    "$$ Y = D \\theta_{0} (X) + g_{0}(X) + \\epsilon$$\n",
    "\n",
    "com  $E(\\epsilon|D,X)=0$, e\n",
    "\n",
    "$$ D = m_{0}(X) + \\eta$$\n",
    "\n",
    "com $E(\\eta|X)=0$.\n",
    "\n",
    "onde $\\theta_{0}(X)$ é o efeito heterogêneo do tratamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passos para a análise. \n",
    "* Carregar o seu conjunto de dados e definir as variáveis relevantes ($X$,$D$,$Y$).\n",
    "* Criar o spline basis usando uma covariável contínua, como você fez anteriormente com mage (ou outra variável relevante).\n",
    "* Estimar o CATE usando o método cate() do DoubleMLPLR.\n",
    "* Gerar o intervalo de confiança para o CATE com splines.\n",
    "* Plotar os resultados comparando o efeito estimado com o intervalo de confiança, similar ao gráfico gerado no exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A learner ml_g has been provided for score = \"partialling out\" but will be ignored. \"A learner ml_g is not required for estimation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               coef    std err         t         P>|t|       2.5 %      97.5 %\n",
      "Treated -189.895808  23.189266 -8.188953  2.635087e-16 -235.345935 -144.445681\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import patsy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "D = \"Treated\"\n",
    "y = \"Y\"\n",
    "X = ['casada', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol',\n",
    "     'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']\n",
    "\n",
    "data_dml_base = dml.DoubleMLData(df, y_col=y, d_cols=D, x_cols=X)\n",
    "\n",
    "# Define the learners for the nuisance functions\n",
    "ml_g = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
    "ml_m = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
    "ml_l = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
    "\n",
    "# Initialize the DoubleMLPLR object with all required learners\n",
    "dml_plr_obj = dml.DoubleMLPLR(data_dml_base, ml_l=ml_l, ml_m=ml_m, ml_g=ml_g)\n",
    "\n",
    "# Fit the model\n",
    "dml_plr_obj.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(dml_plr_obj.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        2.5 %      effect      97.5 %\n",
      "0 -333.531320 -244.434154 -155.336988\n",
      "1 -203.806713 -117.703031  -31.599349\n",
      "2 -261.173404 -189.737681 -118.301958\n",
      "3 -314.616845 -241.854760 -169.092674\n",
      "4 -203.806713 -117.703031  -31.599349\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import doubleml as dml\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Definir os modelos de machine learning\n",
    "ml_g = RandomForestRegressor(n_estimators=100, max_features=20, max_depth=5, min_samples_leaf=2)\n",
    "ml_m = RandomForestRegressor(n_estimators=100, max_features=20, max_depth=5, min_samples_leaf=2)\n",
    "\n",
    "# Definir as variáveis\n",
    "y_col = 'Y'\n",
    "d_col = 'Treated'\n",
    "x_cols = ['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign',\n",
    "          'alcohol', 'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']\n",
    "\n",
    "# Preparar os dados para o DoubleML\n",
    "dml_data = dml.DoubleMLData(df, y_col=y_col, d_cols=d_col, x_cols=x_cols)\n",
    "\n",
    "# Criar o objeto DoubleMLPLR\n",
    "dml_plr_obj = dml.DoubleMLPLR(dml_data, ml_g, ml_m)\n",
    "\n",
    "# Ajustar o modelo\n",
    "_ = dml_plr_obj.fit()\n",
    "\n",
    "# Criar a matriz de design com funções base spline para 'mage'\n",
    "design_matrix = patsy.dmatrix(\"bs(x, df=5, degree=2)\", {\"x\": df[\"mage\"]})\n",
    "spline_basis = pd.DataFrame(design_matrix)\n",
    "\n",
    "#print(spline_basis.head())\n",
    "\n",
    "# Calcular o CATE usando a base spline\n",
    "cate_obj = dml_plr_obj.cate(basis=spline_basis)\n",
    "\n",
    "# Calcular os intervalos de confiança\n",
    "ci = cate_obj.confint(basis=spline_basis)\n",
    "\n",
    "print(ci.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna effect representa a estimativa pontual do efeito do tratamento para cada observação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DoubleMLBLP' object has no attribute 'coef'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cate_coefs \u001b[38;5;241m=\u001b[39m \u001b[43mcate_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef\u001b[49m\n\u001b[0;32m      2\u001b[0m cate_estimates \u001b[38;5;241m=\u001b[39m spline_basis\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m@\u001b[39m cate_coefs\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DoubleMLBLP' object has no attribute 'coef'"
     ]
    }
   ],
   "source": [
    "cate_coefs = cate_obj.coef\n",
    "cate_estimates = spline_basis.values @ cate_coefs\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "cate_variances = np.sum((spline_basis.values @ cate_obj.covariance) * spline_basis.values, axis=1)\n",
    "cate_se = np.sqrt(cate_variances)\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "z_value = norm.ppf(0.975)  # Valor z para um intervalo de confiança de 95%\n",
    "ci_lower = cate_estimates - z_value * cate_se\n",
    "ci_upper = cate_estimates + z_value * cate_se\n",
    "\n",
    "cate_df = pd.DataFrame({\n",
    "    'mage': df['mage'],\n",
    "    'cate': cate_estimates,\n",
    "    'cate_lower': ci_lower,\n",
    "    'cate_upper': ci_upper\n",
    "})\n",
    "\n",
    "# Ordenar os dados por 'mage' para plotagem\n",
    "cate_df_sorted = cate_df.sort_values('mage')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cate_df_sorted['mage'], cate_df_sorted['cate'], label='CATE Estimado')\n",
    "plt.fill_between(cate_df_sorted['mage'], cate_df_sorted['cate_lower'], cate_df_sorted['cate_upper'],\n",
    "                 color='gray', alpha=0.2, label='IC 95%')\n",
    "plt.xlabel('Idade Materna (mage)')\n",
    "plt.ylabel('Efeito do Tratamento Estimado')\n",
    "plt.title('Estimativas do CATE em Função da Idade Materna')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um spline é uma função matemática utilizada para aproximar ou interpolar dados, permitindo modelar relações não lineares de forma flexível. Em essência, splines são combinações de funções polinomiais de baixo grau (como polinômios de grau 2 ou 3) que são unidas em pontos específicos chamados de nós (knots). Esses nós dividem o domínio da variável independente em diferentes intervalos, e em cada intervalo, o spline pode assumir uma forma polinomial diferente, garantindo suavidade nas junções.\n",
    "\n",
    "No contexto da sua análise com o Double Machine Learning (DML), os splines são usados para modelar a heterogeneidade do efeito do tratamento em relação a uma covariável contínua, como a idade materna (mage). Ao utilizar splines, você permite que o efeito estimado do tratamento varie de maneira flexível ao longo dos valores de mage, capturando possíveis relações não lineares entre a idade materna e o efeito do tratamento.\n",
    "\n",
    "Você está criando uma base spline utilizando a função bs() do pacote patsy, que gera splines básicos (basis splines). Aqui, df=5 especifica o número de graus de liberdade, o que influencia o número de nós e, consequentemente, a flexibilidade do spline. degree=2 indica que está utilizando splines quadráticos. A base spline resultante é então utilizada para estimar o CATE, permitindo que o efeito do tratamento varie de forma suave e não linear com mage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### É possivel utilizar DML com dados em painel?\n",
    "\n",
    "Vamos considerar o efeito do homogêneo do tratamento em um painel de dados. No estilo de Sant´Anna e Zhao (2020).\n",
    "\n",
    "Os modelos de diferença em diferenças (DID) implementados no pacote focam no caso de tratamento binário com dois períodos de tratamento. Adotando a notação de Sant'Anna e Zhao (2020) , deixe ser $Y_{it}$ o resultado de interesse para a unidade $i$ no tempo $t$. Além disso, deixe $D_{it}=1$ indicar se unidade $i$ é tratada antes do tempo $t$ (de outra forma $D_{it}=0$). Como todas as unidades começam como não tratadas ($D_{it}=0$), definir $D_{i0}=0$. Com base na notação de resultado potencial, denote $Y_{it}(1)$ como resultado da unidade $i$ no tempo $t$ se a unidade não recebeu tratamento até o momento $t$ e analogamente para $Y_{it}(0)$ com tratamento. Consequentemente, o resultado observado para a unidade $i$ no tempo $t$ é $Y_{it}=Y_{it}(1)D_{it}+Y_{it}(0)(1-D_{it})$. Além disso, deixe $X_{it}$ ser um vetor de covariáveis ​​de pré-tratamento.\n",
    "\n",
    "O parâmetro de interesse é o efeito médio do tratamento no indivíduo tratado (ATTE). \n",
    "\n",
    "$$ \\theta_{ATTE} = E[Y_{i1}(1) - Y_{i1}(0)|D_{it}=1]$$\n",
    "\n",
    "As suposições de identificação correspondentes são:\n",
    "* (Cond.) Tendências paralelas: $Y_{it}(1), Y_{it}(0) \\perp D_{it}|X_{it}$ para $t=1,2$.\n",
    "* Sobreposição: $0 < P(D_{it}=1|X_{it}) < 1$ para $t=1,2$.\n",
    "\n",
    "\n",
    "Se os dados do painel estiverem disponíveis, as observações são consideradas iid. de forma ($Y_{i0},Y_{i1},D_{i},X_{i}$). Obseve que a diferença $\\Delta Y_{i} = Y_{i1} - Y_{i0}$ tem que ser definida como o resultado yno DoubleMLDataobjeto.\n",
    "\n",
    "O DoubleMLIDID implementa modelos de diferença em diferenças para dados de painel. A estimativa é conduzida por meio de seu fit() método:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLDID Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['Z1', 'Z2', 'Z3', 'Z4']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 500\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: observational\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_g: RandomForestRegressor(max_depth=5, min_samples_leaf=5)\n",
      "Learner ml_m: RandomForestClassifier(max_depth=5, min_samples_leaf=5)\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_g0 RMSE: [[16.27429763]]\n",
      "Learner ml_g1 RMSE: [[13.35731523]]\n",
      "Classification:\n",
      "Learner ml_m Log Loss: [[0.66601815]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "       coef   std err         t     P>|t|     2.5 %    97.5 %\n",
      "d -2.840718  1.760386 -1.613691  0.106595 -6.291011  0.609575\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import doubleml as dml\n",
    "from doubleml.datasets import make_did_SZ2020\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "ml_g = RandomForestRegressor(n_estimators=100, max_depth=5, min_samples_leaf=5)\n",
    "ml_m = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_leaf=5)\n",
    "\n",
    "np.random.seed(42)\n",
    "data = make_did_SZ2020(n_obs=500, return_type='DataFrame')\n",
    "obj_dml_data = dml.DoubleMLData(data, 'y', 'd')\n",
    "dml_did_obj = dml.DoubleMLDID(obj_dml_data, ml_g, ml_m)\n",
    "\n",
    "print(dml_did_obj.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Robust Machine Learning - DRML\n",
    "\n",
    "O Double Robust Machine Learning (DRML) é uma extensão do Double Machine Learning (DML) que combina a abordagem de DML com a abordagem de dupla robustez. A dupla robustez é uma propriedade desejável em métodos de estimação causal que garante que o estimador seja consistente se pelo menos um dos modelos de previsão estiver correto. Em outras palavras, um estimador de dupla robustez é robusto a erros de especificação em um dos modelos de previsão.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.dml import LinearDML\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol', \n",
    "     'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']  \n",
    "D = \"Treated\"  \n",
    "y = \"Y\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_y = GradientBoostingRegressor(n_estimators=100, random_state=123)\n",
    "model_t = GradientBoostingRegressor(n_estimators=100, random_state=123)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Coefficient Results                       \n",
      "================================================================\n",
      "          point_estimate  stderr zstat  pvalue ci_lower ci_upper\n",
      "----------------------------------------------------------------\n",
      "casada            24.012  56.382  0.426   0.67  -86.493  134.518\n",
      "mage             -11.978   5.361 -2.234  0.025  -22.485   -1.471\n",
      "medu              13.463  10.551  1.276  0.202   -7.216   34.143\n",
      "fhisp            129.521  134.06  0.966  0.334 -133.232  392.275\n",
      "mhisp            -233.06 163.038 -1.429  0.153 -552.608   86.488\n",
      "foreign          337.961 139.714  2.419  0.016   64.127  611.796\n",
      "alcohol           25.692  98.715   0.26  0.795 -167.785  219.169\n",
      "deadkids           38.43  51.889  0.741  0.459  -63.271  140.132\n",
      "nprenatal        -11.391   6.836 -1.666  0.096   -24.79    2.008\n",
      "mrace           -109.595 102.214 -1.072  0.284  -309.93    90.74\n",
      "frace             33.277 100.759   0.33  0.741 -164.207   230.76\n",
      "fage               0.874   2.824   0.31  0.757   -4.661    6.409\n",
      "fedu               -2.21   7.974 -0.277  0.782  -17.839   13.419\n",
      "                       CATE Intercept Results                      \n",
      "===================================================================\n",
      "               point_estimate stderr zstat pvalue ci_lower ci_upper\n",
      "-------------------------------------------------------------------\n",
      "cate_intercept         76.312 155.82  0.49  0.624 -229.089  381.712\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
      "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
      "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
      "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
      "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n"
     ]
    }
   ],
   "source": [
    "est = LinearDML(model_y=model_y, model_t=model_t, cv=cv, random_state=123)\n",
    "est.fit(Y=df[y], T=df[D], X=df[X])\n",
    "print(est.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n",
      "                       CATE Intercept Results                       \n",
      "====================================================================\n",
      "               point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
      "--------------------------------------------------------------------\n",
      "cate_intercept       -207.258 22.986 -9.017    0.0  -252.31 -162.205\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
      "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
      "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
      "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
      "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n"
     ]
    }
   ],
   "source": [
    "from econml.dml import LinearDML\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Definir D, y e W (covariáveis)\n",
    "D = \"Treated\"\n",
    "y = \"Y\"\n",
    "W = df[['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol',\n",
    "        'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']]\n",
    "\n",
    "# Configurar os modelos de machine learning\n",
    "model_y = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
    "model_t = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
    "\n",
    "# Definir a validação cruzada\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=24)\n",
    "\n",
    "# Instanciar o estimador LinearDML com efeito de tratamento constante\n",
    "est = LinearDML(model_y=model_y,\n",
    "                model_t=model_t,\n",
    "                featurizer=None,\n",
    "                fit_cate_intercept=True,\n",
    "                linear_first_stages=False,\n",
    "                cv=cv,\n",
    "                random_state=24)\n",
    "\n",
    "# Ajustar o modelo\n",
    "est.fit(Y=df[y], T=df[D], X=None, W=W)\n",
    "\n",
    "# Resumo dos resultados\n",
    "print(est.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Coefficient Results                       \n",
      "================================================================\n",
      "          point_estimate  stderr zstat  pvalue ci_lower ci_upper\n",
      "----------------------------------------------------------------\n",
      "casada            24.012  56.382  0.426   0.67  -86.493  134.518\n",
      "mage             -11.978   5.361 -2.234  0.025  -22.485   -1.471\n",
      "medu              13.463  10.551  1.276  0.202   -7.216   34.143\n",
      "fhisp            129.521  134.06  0.966  0.334 -133.232  392.275\n",
      "mhisp            -233.06 163.038 -1.429  0.153 -552.608   86.488\n",
      "foreign          337.961 139.714  2.419  0.016   64.127  611.796\n",
      "alcohol           25.692  98.715   0.26  0.795 -167.785  219.169\n",
      "deadkids           38.43  51.889  0.741  0.459  -63.271  140.132\n",
      "nprenatal        -11.391   6.836 -1.666  0.096   -24.79    2.008\n",
      "mrace           -109.595 102.214 -1.072  0.284  -309.93    90.74\n",
      "frace             33.277 100.759   0.33  0.741 -164.207   230.76\n",
      "fage               0.874   2.824   0.31  0.757   -4.661    6.409\n",
      "fedu               -2.21   7.974 -0.277  0.782  -17.839   13.419\n",
      "                       CATE Intercept Results                      \n",
      "===================================================================\n",
      "               point_estimate stderr zstat pvalue ci_lower ci_upper\n",
      "-------------------------------------------------------------------\n",
      "cate_intercept         76.312 155.82  0.49  0.624 -229.089  381.712\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
      "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
      "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
      "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
      "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n"
     ]
    }
   ],
   "source": [
    "from econml.dml import LinearDML\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Definir X, D, y \n",
    "X = ['casada', 'mage', 'medu', 'fhisp', 'mhisp', 'foreign', 'alcohol', \n",
    "     'deadkids', 'nprenatal', 'mrace', 'frace', 'fage', 'fedu']  \n",
    "D = \"Treated\"  \n",
    "y = \"Y\" \n",
    "\n",
    "# Configurar os modelos para E[Y|X] e E[D|X]\n",
    "model_y = GradientBoostingRegressor(n_estimators=100, random_state=123)\n",
    "model_t = GradientBoostingRegressor(n_estimators=100, random_state=123)\n",
    "\n",
    "# Definir a validação cruzada\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Instanciar o estimador LinearDML com efeito de tratamento constante\n",
    "est = LinearDML(model_y=model_y,\n",
    "                model_t=model_t,\n",
    "                fit_cate_intercept=True,  # Estimar o intercepto do CATE\n",
    "                linear_first_stages=False,\n",
    "                cv=cv,\n",
    "                random_state=123)\n",
    "\n",
    "# Ajustar o modelo\n",
    "est.fit(Y=df[y], T=df[D], X=df[X])  # Definir X=None para o efeito do tratamento constante\n",
    "\n",
    "# Resumo dos resultados\n",
    "print(est.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.dml import LinearDML\n",
    "est = LinearDML()\n",
    "est.fit(y, T, X=X, W=W)\n",
    "est.const_marginal_effect(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### É possivel utilizar DML com dados em painel?\n",
    "\n",
    "Vamos considerar o efeito do homogêneo do tratamento em um painel de dados. No estilo de Sant´Anna e Zhao (2020).\n",
    "\n",
    "Os modelos de diferença em diferenças (DID) implementados no pacote focam no caso de tratamento binário com dois períodos de tratamento. Adotando a notação de Sant'Anna e Zhao (2020) , deixe ser $Y_{it}$ o resultado de interesse para a unidade $i$ no tempo $t$. Além disso, deixe $D_{it}=1$ indicar se unidade $i$ é tratada antes do tempo $t$ (de outra forma $D_{it}=0$). Como todas as unidades começam como não tratadas ($D_{it}=0$), definir $D_{i0}=0$. Com base na notação de resultado potencial, denote $Y_{it}(1)$ como resultado da unidade $i$ no tempo $t$ se a unidade não recebeu tratamento até o momento $t$ e analogamente para $Y_{it}(0)$ com tratamento. Consequentemente, o resultado observado para a unidade $i$ no tempo $t$ é $Y_{it}=Y_{it}(1)D_{it}+Y_{it}(0)(1-D_{it})$. Além disso, deixe $X_{it}$ ser um vetor de covariáveis ​​de pré-tratamento.\n",
    "\n",
    "O parâmetro de interesse é o efeito médio do tratamento no indivíduo tratado (ATTE). \n",
    "\n",
    "$$ \\theta_{ATTE} = E[Y_{i1}(1) - Y_{i1}(0)|D_{it}=1]$$\n",
    "\n",
    "As suposições de identificação correspondentes são:\n",
    "* (Cond.) Tendências paralelas: $Y_{it}(1), Y_{it}(0) \\perp D_{it}|X_{it}$ para $t=1,2$.\n",
    "* Sobreposição: $0 < P(D_{it}=1|X_{it}) < 1$ para $t=1,2$.\n",
    "\n",
    "\n",
    "Se os dados do painel estiverem disponíveis, as observações são consideradas iid. de forma ($Y_{i0},Y_{i1},D_{i},X_{i}$). Obseve que a diferença $\\Delta Y_{i} = Y_{i1} - Y_{i0}$ tem que ser definida como o resultado yno DoubleMLDataobjeto.\n",
    "\n",
    "O DoubleMLIDID implementa modelos de diferença em diferenças para dados de painel. A estimativa é conduzida por meio de seu fit() método:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações Finais\n",
    "\n",
    "* O principal objetivo do DML é ajustar e remover a variável de confusão de forma que a variável de interesse (tratamento) e o desfecho (resultado) fiquem \"ortogonais\" ou \"independentes\".\n",
    "* DML combina métodos de aprendizado de máquina com técnicas econométricas para estimar efeitos causais.\n",
    "* A técnica geralmente envolve a aplicação de aprendizado de máquina para prever tanto o tratamento quanto o desfecho usando variáveis de confusão, e então os resíduos dessas previsões são utilizados em um segundo estágio para estimar o efeito causal.\n",
    "  * Primeiro Estágio: Aplicar modelos de aprendizado de máquina para prever a variável de tratamento e o resultado.\n",
    "  * Segundo Estágio: Utilizar os resíduos dessas previsões em um modelo de regressão para estimar o efeito causal.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doubly Robust Machine Learning (DRML)\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "DRML visa fornecer estimativas consistentes do efeito causal mesmo que uma das duas especificações de modelo (do tratamento ou do desfecho) esteja incorreta.\n",
    "Abordagem:\n",
    "\n",
    "A metodologia DRML combina a ponderação de probabilidade inversa (IPW) com métodos de regressão.\n",
    "Essa abordagem é \"duplamente robusta\" porque, para a consistência da estimativa, é necessário que apenas um dos modelos - ou o modelo de probabilidade de tratamento (propensity score) ou o modelo de desfecho (outcome model) - esteja corretamente especificado.\n",
    "Implementação:\n",
    "\n",
    "Modelagem do Propensity Score: Estimar a probabilidade de cada unidade receber o tratamento.\n",
    "Modelagem do Desfecho: Estimar o desfecho esperado condicional ao tratamento e às covariáveis.\n",
    "Combinação dos Modelos: Utilizar uma combinação das estimativas dos dois modelos para obter uma estimativa do efeito causal que é robusta a erros na especificação de um dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resumo Comparativo: DML vs DRML\n",
    "\n",
    "* DML: Foca na remoção de viés através de uma abordagem em dois estágios, utilizando previsões de aprendizado de máquina e resíduos. Busca a ortogonalidade entre o tratamento e o desfecho.\n",
    "* DRML: Utiliza a ponderação de probabilidade inversa e a modelagem do desfecho para obter estimativas robustas. É duplamente robusta porque requer que apenas um dos dois modelos esteja corretamente especificado.\n",
    "\n",
    "Ambas as metodologias são úteis em inferência causal e se beneficiam da flexibilidade e poder dos métodos de aprendizado de máquina, mas cada uma tem suas especificidades e contextos de aplicação onde são mais adequadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
