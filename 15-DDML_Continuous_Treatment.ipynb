{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Debiased Machine Learning for Continuous Treatments\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    "* Double Debiased Machine Learning for Continuous Treatments - DDML for Continuous Treatments\n",
    "\n",
    "\n",
    "## Referências\n",
    "\n",
    "**Principais:**\n",
    "* Colangelo and Lee (2023). Double Debiased Machine Learning Nonparametric Inference with Continuous Treatments. [arXiv:2004.03036v8 ](https://doi.org/10.48550/arXiv.2004.03036) \n",
    "* GitHub: https://github.com/KColangelo/Double-ML-Continuous-Treatment\n",
    "* \n",
    "**Complementares:**\n",
    "* Microsoft EconML: https://econml.azurewebsites.net/\n",
    "* UBER CausalML: https://causalml.readthedocs.io/en/latest/\n",
    "* https://docs.doubleml.org/stable/index.html\n",
    "* https://github.com/MasaAsami/ReproducingDMLDiD/blob/main/notebook/Reproduction_of_DMLDiD_RO_for_NEW_SIMDATA.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "# Double Debiased Machine Learning for Continuous Treatments\n",
    "\n",
    "## Introdução\n",
    "\n",
    "O **Double Debiased Machine Learning (DML)** é um método estatístico robusto e eficiente para estimar efeitos causais em contextos onde o tratamento é uma variável contínua. Este método combina:\n",
    "- **Momentos Duplamente Robustos**, que garantem consistência mesmo quando uma das funções auxiliares é mal especificada.\n",
    "- **Cross-fitting**, para evitar viés de overfitting causado pelo uso do mesmo conjunto de dados para treinamento e inferência.\n",
    "- **Métodos de Machine Learning (ML)**, como LASSO, Redes Neurais ou Random Forests, para modelar funções de expectativa condicional e densidades condicionais.\n",
    "\n",
    "O método é especialmente adequado para cenários onde o número de covariáveis é grande (alta dimensionalidade), sendo robusto a especificações incorretas de uma das funções auxiliares.\n",
    "\n",
    "---\n",
    "\n",
    "## Estrutura do Problema\n",
    "\n",
    "### Dados e Objetivos\n",
    "\n",
    "Considere uma amostra $\\{Y_i, T_i, X_i\\}_{i=1}^n$, onde:\n",
    "- $Y_i$: Desfecho de interesse (variável dependente).\n",
    "- $T_i$: Tratamento contínuo.\n",
    "- $X_i$: Covariáveis observadas (potencialmente de alta dimensionalidade).\n",
    "\n",
    "O objetivo principal é estimar:\n",
    "1. **Função de Resposta Média à Dose (Average Dose-Response Function - ADRF)**:\n",
    "   $$\n",
    "   \\beta_t = \\mathbb{E}[Y(t)],\n",
    "   $$\n",
    "   onde $Y(t)$ representa o desfecho potencial para um valor específico $t$ do tratamento.\n",
    "\n",
    "2. **Efeito Marginal (Partial Effect)**:\n",
    "   $$\n",
    "   \\theta_t = \\frac{\\partial \\beta_t}{\\partial t}.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "## Suposições para Identificação\n",
    "\n",
    "Para identificar os efeitos causais, assumimos:\n",
    "1. **Independência Condicional (Unconfoundedness)**:\n",
    "   $$\n",
    "   T \\perp \\varepsilon \\mid X,\n",
    "   $$\n",
    "   onde $\\varepsilon$ é o erro não observado. Esta suposição implica que, condicional nas covariáveis $X$, o tratamento é independentemente alocado.\n",
    "\n",
    "2. **Suporte Comum (Common Support)**:\n",
    "   $$\n",
    "   f_{T|X}(t \\mid X) > 0, \\quad \\forall t \\in \\mathcal{T}.\n",
    "   $$\n",
    "   Esta condição assegura que há sobreposição suficiente entre grupos de tratamento.\n",
    "\n",
    "---\n",
    "\n",
    "## Estimador DML\n",
    "\n",
    "O estimador baseia-se em uma função momento duplamente robusta, definida como:\n",
    "$$\n",
    "\\psi_t(Y_i, T_i, X_i) = \\gamma(t, X_i) + \\frac{K_h(T_i - t)}{f_{T|X}(t \\mid X_i)} \\left(Y_i - \\gamma(t, X_i)\\right),\n",
    "$$\n",
    "onde:\n",
    "- $\\gamma(t, X) = \\mathbb{E}[Y \\mid T = t, X]$: Expectativa condicional.\n",
    "- $f_{T|X}(t \\mid X)$: Densidade condicional do tratamento.\n",
    "- $K_h(T_i - t)$: Função kernel para ponderar observações próximas do valor de tratamento $t$.\n",
    "\n",
    "O estimador para $\\beta_t$ é dado por:\n",
    "$$\n",
    "\\hat{\\beta}_t = \\frac{1}{n} \\sum_{i=1}^n \\psi_t(Y_i, T_i, X_i).\n",
    "$$\n",
    "\n",
    "### Cross-Fitting\n",
    "Para evitar viés de overfitting, os dados são particionados em $L$ subconjuntos (folds). Para cada fold $\\ell$, as funções $\\gamma$ e $f_{T|X}$ são estimadas usando apenas os dados fora do fold $\\ell$. O estimador final é obtido pela média das estimativas em cada fold:\n",
    "$$\n",
    "\\hat{\\beta}_t = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\gamma_{-\\ell}(t, X_i) + \\frac{K_h(T_i - t)}{f_{T|X,-\\ell}(t \\mid X_i)} \\left(Y_i - \\gamma_{-\\ell}(t, X_i)\\right) \\right].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Propriedades Assintóticas\n",
    "\n",
    "Sob condições regulares, o estimador $\\hat{\\beta}_t$ é:\n",
    "1. **Consistente**: Converge para o valor verdadeiro $\\beta_t$.\n",
    "2. **Assintoticamente Normal**:\n",
    "   $$\n",
    "   \\sqrt{n} (\\hat{\\beta}_t - \\beta_t) \\xrightarrow{d} N(0, V_t),\n",
    "   $$\n",
    "   onde $V_t$ é a variância assintótica, que pode ser estimada como:\n",
    "   $$\n",
    "   \\hat{V}_t = \\frac{1}{n^2} \\sum_{i=1}^n \\psi_t^2(Y_i, T_i, X_i).\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "## Estimação do Efeito Marginal\n",
    "\n",
    "O efeito marginal $\\theta_t$ é estimado numericamente:\n",
    "$$\n",
    "\\hat{\\theta}_t = \\frac{\\hat{\\beta}_{t + \\eta/2} - \\hat{\\beta}_{t - \\eta/2}}{\\eta},\n",
    "$$\n",
    "onde $\\eta$ é uma sequência positiva que converge para zero à medida que $n \\to \\infty$.\n",
    "\n",
    "Para garantir consistência e eficiência, $\\eta$ deve ser escolhida adequadamente, levando em conta o tamanho amostral e a variabilidade nas estimativas de $\\beta_t$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefícios e Limitações\n",
    "\n",
    "### Benefícios\n",
    "- **Flexibilidade**: Permite o uso de métodos de aprendizado de máquina para modelar $\\gamma$ e $f_{T|X}$.\n",
    "- **Eficiência**: Utiliza técnicas como cross-fitting para melhorar a precisão das estimativas.\n",
    "- **Robustez**: Resistente a erros de especificação em uma das funções auxiliares.\n",
    "\n",
    "### Limitações\n",
    "- **Complexidade Computacional**: Requer a estimativa de funções auxiliares de alta dimensionalidade.\n",
    "- **Sensibilidade ao Kernel**: A escolha do kernel e da largura de banda ($h$) pode impactar os resultados.\n",
    "\n",
    "---\n",
    "\n",
    "## Exemplo Intuitivo\n",
    "\n",
    "Considere um estudo que analisa o impacto de **horas de treinamento em um programa de capacitação** ($T$) nos **salários futuros** ($Y$):\n",
    "- Usamos $\\gamma(t, X)$ para prever salários dados $T$ e as covariáveis $X$ (e.g., idade, escolaridade).\n",
    "- Estimamos $f_{T|X}(t \\mid X)$, que captura a distribuição das horas de treinamento, dado o perfil do indivíduo.\n",
    "- O DML ajusta as estimativas para isolar o impacto causal de $T$ em $Y$, mesmo que algumas relações sejam complexas ou não lineares.\n",
    "\n",
    "---\n",
    "\n",
    "## Considerações Finais\n",
    "O Double Debiased Machine Learning é um método avançado para estimar efeitos causais com tratamentos contínuos, oferecendo:\n",
    "\n",
    "* Robustez a especificações incorretas de modelos auxiliares.\n",
    "* Flexibilidade no uso de métodos de ML para modelagem de alta dimensionalidade.\n",
    "* Garantias teóricas de consistência e normalidade assintótica.\n",
    "\n",
    "Este método é ideal para aplicações empíricas que exigem alto rigor estatístico, como estudos em economia, saúde e políticas públicas.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
