{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Robust Machine Learning, Double Machine Learning-DD, & Double Robust Machine Learning-IV\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    "* Double Robust Machine Learning (DRML)\n",
    "* Double Robust Machine Learning Difference-in-Differences (DRML-DiD)\n",
    "* Double Robust Machine Learning IV (DRML-IV)\n",
    "\n",
    "\n",
    "## Referências\n",
    "\n",
    "**Principais:**\n",
    "* Microsoft EconML: https://econml.azurewebsites.net/\n",
    "* UBER CausalML: https://causalml.readthedocs.io/en/latest/\n",
    "* https://docs.doubleml.org/stable/index.html\n",
    "* https://github.com/MasaAsami/ReproducingDMLDiD/blob/main/notebook/Reproduction_of_DMLDiD_RO_for_NEW_SIMDATA.ipynb\n",
    "* Schmidheiny, K., & Siegloch, S. (2023). On event studies and distributed-lags in two-way fixed effects models: Identification, equivalence, and generalization. Journal of Applied Econometrics, 1- 19. https://doi.org/10.1002/jae.2971\n",
    "* Stevenson, Betsey, Wolfers, Justin, 2006. Bargaining in the shadow of the law: Divorce laws and family distress. Q. J. Econ. 121 (1), 267–288.\n",
    "* Goodman-Bacon, A. (2021). Difference-in-differences with variation in treatment timing. Journal of Econometrics. https://doi.org/10.1016/j.jeconom.2021.03.014\n",
    "* Callaway, B. and Sant'Anna, P. H. C. (2021). Difference-in-Differences with multiple time periods. Journal of Econometrics. https://doi.org/10.1016/j.jeconom.2020.12.001\n",
    "\n",
    "**Complementares:**\n",
    "\n",
    "* Borusyak, K.; Jaravel, X. and Spiess, J. (2023). Revisiting Event Study Designs: Robust and Efficient Estimation. arXiv: https://arxiv.org/pdf/2108.12419.pdf\n",
    "* Clément deChaisemartin, Xavier d’Haultfoeuille. (2022) Difference-in-Differences Estimators of Intertemporal Treatment Effects. hal-03873903\n",
    "* Roth et al. (2022) What’s Trending in Difference-in-Differences? A Synthesis of the Recent Econometrics Literature. https://www.jonathandroth.com/assets/files/DiD_Review_Paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Robust Machine Learning (DRML)\n",
    "\n",
    "O estimador duplamente robusto para o Conditional Average Treatment Effect (CATE) combina modelos de *Outcome Regression* e de *escore de propensão* para fornecer estimativas consistentes, mesmo que um dos modelos seja mal especificado. A fórmula geral é:\n",
    "\n",
    "$$\n",
    "\\hat{\\tau}(X_i) = \\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i) + \\frac{D_i - \\hat{p}(X_i)}{\\hat{p}(X_i)(1 - \\hat{p}(X_i))}(Y_i - \\hat{\\mu}_{D_i}(X_i)),\n",
    "$$\n",
    "\n",
    "onde:\n",
    "- $ \\hat{\\mu}_d(X_i) = \\mathbb{E}[Y_i \\mid X_i, D_i = d] $ é a estimativa do desfecho esperado para o tratamento $ d $ dado $ X_i $\n",
    "- $ \\hat{p}(X_i) = \\mathbb{P}(D_i = 1 \\mid X_i) $ é a estimativa do escore de propensão, ou seja, a probabilidade de receber o tratamento dado $ X_i $\n",
    "- $ D_i $ é a variável indicadora de tratamento (1 se tratado, 0 caso contrário),\n",
    "- $ Y_i $ é o desfecho observado.\n",
    "\n",
    "---\n",
    "\n",
    "### Processo de Estimação\n",
    "\n",
    "#### Primeiro Estágio: Estimação das Funções Incômodas\n",
    "\n",
    "1. **Modelo de Desfecho ($ \\hat{\\mu}_d(X_i) $)**:  \n",
    "   Estima-se a relação entre as covariáveis $ X_i $ e o desfecho $ Y_i $ para cada nível de tratamento $ d $.  \n",
    "   Técnicas de aprendizado de máquina, como regressão linear, árvores de decisão ou redes neurais, podem ser utilizadas.\n",
    "\n",
    "2. **Modelo de Escore de Propensão ($ \\hat{p}(X_i) $)**:  \n",
    "   Estima-se a probabilidade de um indivíduo receber o tratamento dado $ X_i $.  \n",
    "   Modelos como regressão logística ou métodos de classificação podem ser aplicados.\n",
    "\n",
    "#### Segundo Estágio: Cálculo do Estimador Duplamente Robusto\n",
    "\n",
    "Utiliza-se a fórmula acima para calcular $ \\hat{\\tau}(X_i) $ para cada indivíduo, combinando as estimativas dos modelos de desfecho e de escore de propensão.\n",
    "\n",
    "---\n",
    "\n",
    "### Propriedades do Estimador Duplamente Robusto\n",
    "\n",
    "1. **Robustez Dupla**:  \n",
    "   O estimador $ \\hat{\\tau}(X_i) $ é consistente se pelo menos um dos modelos (desfecho ou escore de propensão) for corretamente especificado.  \n",
    "   Isso significa que erros em um modelo podem ser compensados pela precisão do outro.\n",
    "\n",
    "2. **Eficiência**:  \n",
    "   Quando ambos os modelos são corretamente especificados, o estimador atinge eficiência assintótica, resultando em estimativas mais precisas.\n",
    "\n",
    "---\n",
    "\n",
    "### Implementação Prática\n",
    "\n",
    "Na prática, é comum utilizar técnicas de *cross-fitting* para evitar viés de superajuste. O procedimento envolve dividir os dados em folds, ajustando os modelos de desfecho e escore de propensão em uma parte dos dados e validando em outra, garantindo que as estimativas sejam independentes dos dados usados para ajuste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Robust Machine Learning - DRML\n",
    "\n",
    "O Estimador de DRML para o Conditional Average Treatment Effect (CATE) utiliza uma abordagem duplamente robusta para controlar o viés de seleção do tratamento. O estimador segue um processo de dois estágios: no primeiro, estimam-se as funções incômodas usando técnicas de *crossfitting*, e, no segundo, estima-se o CATE a partir das funções ajustadas.\n",
    "\n",
    "O estimador pode ser descrito pelas seguintes equações:\n",
    "\n",
    "#### Estimativa Duplamente Robusta para $ Y_{t}^{DR} $\n",
    "\n",
    "$$ \\hat{Y}_{i,t}^{DR} = \\mu_t(X_i, W_i) + \\frac{D_i}{\\hat{p}_t(X_i, W_i)} \\cdot (Y_i - \\mu_t(X_i, W_i)), $$\n",
    "\n",
    "onde:\n",
    "- $ \\mu_t(X_i, W_i) = \\mathbb{E}[Y | X_i, W_i, T_i = t] $ é a função de resultado condicional,\n",
    "- $ \\hat{p}_t(X_i, W_i) = \\mathbb{P}[T_i = t | X_i, W_i] $ é o escore de propensão condicional,\n",
    "- $ D_i = 1[T_i = t] $ é uma variável indicadora para o tratamento $ t $\n",
    "\n",
    "#### Estimativa do CATE\n",
    "\n",
    "$$ \\theta_t(X_i) = \\mathbb{E}[\\hat{Y}_{i,t}^{DR} - \\hat{Y}_{i,0}^{DR} | X_i], $$\n",
    "\n",
    "onde $ \\hat{Y}_{i,0}^{DR} $ é o contrafactual correspondente ao tratamento de referência $ t = 0 $\n",
    "\n",
    "---\n",
    "\n",
    "### Processo de Estimação\n",
    "\n",
    "1. **Primeiro estágio**:  \n",
    "   Estimam-se as funções incômodas $ \\mu_t(X, W) $ e $ \\hat{p}_t(X, W) $ usando técnicas de aprendizado de máquina em um esquema de *crossfitting* para evitar viés.\n",
    "\n",
    "2. **Segundo estágio**:  \n",
    "   Substitui-se as estimativas obtidas no primeiro estágio nas equações acima e calcula-se o CATE ajustado para cada tratamento $ t $ resolvendo a regressão de $ \\hat{Y}_{i,t}^{DR} - \\hat{Y}_{i,0}^{DR} $ sobre $ X_i $\n",
    "\n",
    "---\n",
    "\n",
    "### Observações\n",
    "\n",
    "- **Robustez**: A abordagem é robusta contra erros na especificação de $ \\mu_t(X, W) $ ou $ \\hat{p}_t(X, W) $, desde que pelo menos uma delas seja corretamente especificada.\n",
    "- **Viés residual**: A precisão da estimativa depende fortemente da qualidade das funções incômodas ajustadas no primeiro estágio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "### Double Robust Machine Learning - DRML\n",
    "\n",
    "O Estimador de DRML para o CATE usa técnicas de correção duplamente robustas para controlar o viés de seleção do tratamento. O estimador segue um processo de dois estágios, onde um conjunto de funções incômodas (não especificado, mas que deve ser considerado no modelo) são estimadas no primeiro estágio de uma maneira de *crossfitting* e no segundo estágio estima-se o modelo CATE. \n",
    "\n",
    "Ou seja, neste estimador, o CATE é estimado usando as seguintes equações:\n",
    "\n",
    "$$ Y_{i,t}^{DR} = E[Y|X_{i}, W_{i}, T_{i}=t] + \\frac{Y_{i} - E[Y|X_{i}, W_{i}, T_{i}=t]}{Pr[T_{i}=t|X_{i}, W_{i}]}.1[T_{i}=t] $$\n",
    " \n",
    "Então,\n",
    "\n",
    "$$ E[Y_{i,t}^{DR}-Y_{i,0}^{DR}|X_{i}] = \\theta_{t}(X_{i}) $$\n",
    "\n",
    "\n",
    "Então, se estimarmos as funções $E[Y|X, W, T]$ e $Pr[T|X, W]$ no primeiro estágio, podemos estimar o segundo estágio CATE para cada tratamento $t$, rodando uma regressão $Y_{i,t}^{DR} - Y_{i,0}^{DR}$ sobre $X$.\n",
    "\n",
    "Os possíveis problemas de estimar a função do propensity score recai na definição arbitrária do modelo de \"classificação\". A segunda função é uma regressão simples em $Y$.\n",
    "\n",
    "\n",
    "https://econml.azurewebsites.net/_autosummary/econml.dr.DRLearner.html\n",
    "\n",
    "\n",
    "Outros Modelos Duplamente robustos similares podem ser aplicados:\n",
    "* econml.dr.DRLearner (visto aqui)\n",
    "  * Estimador CATE que usa técnicas de correção duplamente robustas para contabilizar o viés de seleção em variáveis observáveis no tratamento.\n",
    "* econml.dr.LinearDRLearner\n",
    "  * Caso especial em DRLearner que o estágio final é uma Regressão Linear em um conjunto de recursos de baixa dimensão.\n",
    "* econml.dr.SparseLinearDRLearner\n",
    "  * Caso especial em DRLearner que o estágio final é uma Regressão Lasso Desviada.\n",
    "* econml.dr.ForestDRLearner\n",
    "  * Instância do DRLearner com a RegressionForest como modelo final, para permitir inferência não paramétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "### Doble Robust Machine Learning Difference-in-Differences (DRMLDiD)\n",
    "\n",
    "**É possivel utilizar DML com dados em painel?**\n",
    "\n",
    "Antes de avançar para o DRMLDiD, vamos primeiro entender como o DML pode ser aplicado a dados em painel (DMLDiD).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Vamos considerar o efeito do homogêneo do tratamento em um painel de dados. No estilo de Sant´Anna e Zhao (2020).\n",
    "\n",
    "Os modelos de diferença em diferenças (DID) implementados no pacote focam no caso de tratamento binário com dois períodos de tratamento. Adotando a notação de Sant'Anna e Zhao (2020) , deixe ser $Y_{it}$ o resultado de interesse para a unidade $i$ no tempo $t$. Além disso, deixe $D_{it}=1$ indicar se unidade $i$ é tratada antes do tempo $t$ (de outra forma $D_{it}=0$). Como todas as unidades começam como não tratadas ($D_{it}=0$), definir $D_{i0}=0$. Com base na notação de resultado potencial, denote $Y_{it}(1)$ como resultado da unidade $i$ no tempo $t$ se a unidade não recebeu tratamento até o momento $t$ e analogamente para $Y_{it}(0)$ com tratamento. Consequentemente, o resultado observado para a unidade $i$ no tempo $t$ é $Y_{it}=Y_{it}(1)D_{it}+Y_{it}(0)(1-D_{it})$. Além disso, deixe $X_{it}$ ser um vetor de covariáveis ​​de pré-tratamento.\n",
    "\n",
    "O parâmetro de interesse é o efeito médio do tratamento no indivíduo tratado (ATTE). \n",
    "\n",
    "$$ \\theta_{ATTE} = E[Y_{i1}(1) - Y_{i1}(0)|D_{it}=1]$$\n",
    "\n",
    "As suposições de identificação correspondentes são:\n",
    "* (Cond.) Tendências paralelas: $Y_{it}(1), Y_{it}(0) \\perp D_{it}|X_{it}$ para $t=1,2$.\n",
    "* Sobreposição: $0 < P(D_{it}=1|X_{it}) < 1$ para $t=1,2$.\n",
    "\n",
    "\n",
    "Se os dados do painel estiverem disponíveis, as observações são consideradas iid. de forma ($Y_{i0},Y_{i1},D_{i},X_{i}$). Obseve que a diferença $\\Delta Y_{i} = Y_{i1} - Y_{i0}$ tem que ser definida como o resultado yno DoubleMLDataobjeto.\n",
    "\n",
    "O DoubleMLIDID implementa modelos de diferença em diferenças para dados de painel. A estimativa é conduzida por meio de seu fit() método:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLDID Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['Z1', 'Z2', 'Z3', 'Z4']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 500\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: observational\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_g: RandomForestRegressor(max_depth=5, min_samples_leaf=5)\n",
      "Learner ml_m: RandomForestClassifier(max_depth=5, min_samples_leaf=5)\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_g0 RMSE: [[16.27429763]]\n",
      "Learner ml_g1 RMSE: [[13.35731523]]\n",
      "Classification:\n",
      "Learner ml_m Log Loss: [[0.66601815]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "       coef   std err         t     P>|t|     2.5 %    97.5 %\n",
      "d -2.840718  1.760386 -1.613691  0.106595 -6.291011  0.609575\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import doubleml as dml\n",
    "from doubleml.datasets import make_did_SZ2020\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "ml_g = RandomForestRegressor(n_estimators=100, max_depth=5, min_samples_leaf=5)\n",
    "ml_m = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_leaf=5)\n",
    "\n",
    "np.random.seed(42)\n",
    "data = make_did_SZ2020(n_obs=500, return_type='DataFrame')\n",
    "obj_dml_data = dml.DoubleMLData(data, 'y', 'd')\n",
    "dml_did_obj = dml.DoubleMLDID(obj_dml_data, ml_g, ml_m)\n",
    "\n",
    "print(dml_did_obj.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Robust Machine Learning - DRML\n",
    "\n",
    "O Estimador de DRML para o CATE usa técnicas de correção duplamente robustas para controlar o viés de seleção do tratamento. O estimador segue um processo de dois estágios, onde um conjunto de funções incômodas (não especificado, mas que deve ser considerado no modelo) são estimadas no primeiro estágio de uma maneira de *crossfitting* e no segundo estágio estima-se o modelo CATE. \n",
    "\n",
    "Ou seja, neste estimador, o CATE é estimado usando as seguintes equações:\n",
    "\n",
    "$$ Y_{i,t}^{DR} = E[Y|X_{i}, W_{i}, T_{i}=t] + \\frac{Y_{i} - E[Y|X_{i}, W_{i}, T_{i}=t]}{Pr[T_{i}=t|X_{i}, W_{i}]}.1[T_{i}=t] $$\n",
    " \n",
    "Então,\n",
    "\n",
    "$$ E[Y_{i,t}^{DR}-Y_{i,0}^{DR}|X_{i}] = \\theta_{t}(X_{i}) $$\n",
    "\n",
    "\n",
    "Então, se estimarmos as funções $E[Y|X, W, T]$ e $Pr[T|X, W]$ no primeiro estágio, podemos estimar o segundo estágio CATE para cada tratamento $t$, rodando uma regressão $Y_{i,t}^{DR} - Y_{i,0}^{DR}$ sobre $X$.\n",
    "\n",
    "Os possíveis problemas de estimar a função do propensity score recai na definição arbitrária do modelo de \"classificação\". A segunda função é uma regressão simples em $Y$.\n",
    "\n",
    "\n",
    "https://econml.azurewebsites.net/_autosummary/econml.dr.DRLearner.html\n",
    "\n",
    "\n",
    "Outros Modelos Duplamente robustos similares podem ser aplicados:\n",
    "* econml.dr.DRLearner (visto aqui)\n",
    "  * Estimador CATE que usa técnicas de correção duplamente robustas para contabilizar o viés de seleção em variáveis observáveis no tratamento.\n",
    "* econml.dr.LinearDRLearner\n",
    "  * Caso especial em DRLearner que o estágio final é uma Regressão Linear em um conjunto de recursos de baixa dimensão.\n",
    "* econml.dr.SparseLinearDRLearner\n",
    "  * Caso especial em DRLearner que o estágio final é uma Regressão Lasso Desviada.\n",
    "* econml.dr.ForestDRLearner\n",
    "  * Instância do DRLearner com a RegressionForest como modelo final, para permitir inferência não paramétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "#### Resumo Comparativo: DML vs DRML\n",
    "\n",
    "* DML: Foca na remoção de viés através de uma abordagem em dois estágios, utilizando previsões de aprendizado de máquina e resíduos. Busca a ortogonalidade entre o tratamento e o desfecho.\n",
    "* DRML: Utiliza a ponderação de probabilidade inversa e a modelagem do desfecho para obter estimativas robustas. É duplamente robusta porque requer que apenas um dos dois modelos esteja corretamente especificado.\n",
    "\n",
    "Ambas as metodologias são úteis em inferência causal e se beneficiam da flexibilidade e poder dos métodos de aprendizado de máquina, mas cada uma tem suas especificidades e contextos de aplicação onde são mais adequadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
